<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="theme-color" content="#3367D6"/>
  <link rel="apple-touch-icon" href="/icons-192.png">
  <link rel="manifest" href="/manifest.json">
  
  <meta name="generator" content="Hexo 5.4.0">

  

  

  
    <meta name="author" content="sterne">
  

  

  

  <title>数字图像处理 | Welcome -Sterne&#39;s Blog-</title>

  

  
    <link rel="shortcut icon" href="/favicon.ico">
  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@1.1.3/index.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlightjs@9.16.2/styles/monokai.css">
  

  
<link rel="stylesheet" href="/css/style.css">

<link rel="alternate" href="/atom.xml" title="Welcome -Sterne's Blog-" type="application/atom+xml">
</head>
<body>
  <div class="root-container">
    
<!-- header container -->
<header class="header-container post">
  
    <div class="post-image" style="background-image: url(/img/cover.jpg)"></div>
  

  <!-- navbar -->
<nav class="navbar">
  <div class="navbar-content">
    <!-- logo -->
    <div class="navbar-logo">
      <a href="/">
        
          Welcome -Sterne&#39;s Blog-
        
      </a>
    </div>
    <!-- link -->
    <div class="navbar-link">
      <div class="navbar-btn">
        <div></div>
        <div></div>
        <div></div>
      </div>
      <ul class="navbar-list">
        
          <li class="navbar-list-item"><a href="/">Home</a></li>
        
          <li class="navbar-list-item"><a href="/links">Links</a></li>
        
          <li class="navbar-list-item"><a href="/about">About</a></li>
        
      </ul>
    </div>
  </div>
</nav>

  
  

  
  

  
  

  
  

  
  
    <div class="header-content">
      <div class="post-text layout-block">
        <div class="layout-margin">
          <h1 class="title-wrap">数字图像处理</h1>
          <h2 class="title-sub-wrap">
            <strong>sterne</strong>
            <span>发布于</span>
            <time  class="article-date" datetime="2022-11-30T07:55:02.000Z" itemprop="datePublished">2022-11-30</time>
          </h2>
          <ul class="wrap-list dark">
  
</ul>
          <ul class="wrap-list dark">
  
    <li><a href="/tags/python/">🏷️ python</a></li>
  
</ul>
        </div>
      </div>
    </div>
  

  
  
  
</header>

    <!-- 文章 -->

<!-- 文章内容 -->
<div class="body-container">
  <article class="content-container layout-block post-container">
    <div class="article-info">
      
      
      
      
      <section class="article-entry markdown-body layout-margin content-padding--large soft-size--large soft-style--box">
        <h1 id="Chapter1-绪论"><a href="#Chapter1-绪论" class="headerlink" title="Chapter1.绪论"></a>Chapter1.绪论</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>数字图像处理（Digital Image Processing）：指借用数字计算机处理数字图像。</p>
<p>数字图像：用一个数字阵列来表示的图像。数字图像是图像的数值表示，像素是最小单位。数字图像是相对于模拟图像（？）来说的</p>
<p>图像：图像是对客观存在物体的一种相似性的生动模仿与描述，是一种直观化的描述、写真或模拟。简言之，是客观世界的仿真。</p>
<h2 id="图像的分类"><a href="#图像的分类" class="headerlink" title="图像的分类"></a>图像的分类</h2><p>按照图像的实际客观存在分</p>
<ol>
<li>物理图像：指物质或能量的实际分布。<ul>
<li>可见图像：人眼可见的图像，包括光学图像，人工生成的图像，照片、绘画</li>
<li>不可见的物理图像：可测的物理特征量的空间分布所构成的图像。通过可视化手段将其改造成肉眼可识别的图像。如人口密度图、压力图等。</li>
</ul>
</li>
<li>虚拟图像：采用数学方法，将概念形成的物体（非实物）进行表示的图像。虚拟图像是利用数学模型生成的图像。关键问题：能否具有真实图像的真实感。</li>
</ol>
<p>按图像空间坐标和幅度（亮度和色彩）的连续性分</p>
<ol>
<li>模拟图像：空间坐标和幅度都连续变化的图像。I=F(x,y)</li>
<li>数字图像：空间坐标和幅度都用离散的数字（一般是整数）表示的图像。数字阵列来表示图像，每个数字都表示图像的一个像素。对每个像素点的颜色、亮度的数字化描述，就可得到在计算机上处理的数字图像。</li>
</ol>
<img src="/2022/11/30/ImageProc/image-20221130165412955.png" class="" title="image-20221130165412955">

<h2 id="数字图像的描述"><a href="#数字图像的描述" class="headerlink" title="数字图像的描述"></a>数字图像的描述</h2><p>I=F(x,y)</p>
<p>x,y是空间坐标，幅值f称为该点图像的强度或灰度。</p>
<p>可以用矩阵/向量/数组描述。</p>
<h2 id="矩阵坐标系、直角坐标系"><a href="#矩阵坐标系、直角坐标系" class="headerlink" title="矩阵坐标系、直角坐标系"></a>矩阵坐标系、直角坐标系</h2><img src="/2022/11/30/ImageProc/image-20221130170449712.png" class="" title="image-20221130170449712">

<p>a：矩阵坐标系，常用于屏幕显示</p>
<p>b：直角坐标系，常用于图像计算</p>
<h2 id="图像处理分类"><a href="#图像处理分类" class="headerlink" title="图像处理分类"></a>图像处理分类</h2><ol>
<li><p>模拟图像处理</p>
<p>利用光学、电子学对模拟图像进行处理。优点：处理速度快、信息容量大、经济</p>
</li>
<li><p>数字图像处理</p>
<p>利用数字化技术对数字图像进行处理的过程和方法。优点：精度高、处理方便、重复性好</p>
</li>
</ol>
<p>补充：数字图像处理、计算机视觉、计算机图形学关系</p>
<p> 计算机视觉：计算机视觉的目的是发展出能够理解自然景物的系统。在机器人领域中，计算机视觉为机器人提供眼睛的功能。</p>
<p> 计算机图形学：用计算机将由概念所表示的物体（不是实物）图像进行处理和显示。侧重于根据给定的物体描述模型、光照及想象中的摄像机的成像几何，生成一幅图像</p>
<h2 id="图像处理方法"><a href="#图像处理方法" class="headerlink" title="图像处理方法"></a>图像处理方法</h2><h3 id="空域法"><a href="#空域法" class="headerlink" title="空域法"></a>空域法</h3><p>处理点阵的方法，又可分为</p>
<ul>
<li>邻域处理法<ul>
<li>梯度运算（一阶微分算子）</li>
<li>拉普拉斯算子运算（二阶微分）</li>
<li>平滑算子运算</li>
<li>卷积运算</li>
</ul>
</li>
<li>点处理法<ul>
<li>灰度处理</li>
<li>面积、周长、体积、重心运算（？）</li>
</ul>
</li>
</ul>
<h3 id="变换域法"><a href="#变换域法" class="headerlink" title="变换域法"></a>变换域法</h3><p>首先对图像进行正交变换，得到变换域系数阵列，然后再进行各种处理，处理后再反变换到空间域，得到处理结果</p>
<ul>
<li>滤波</li>
<li>数据压缩</li>
<li>特征提取</li>
</ul>
<h1 id="Chapter2-图像处理基础"><a href="#Chapter2-图像处理基础" class="headerlink" title="Chapter2.图像处理基础"></a>Chapter2.图像处理基础</h1><h2 id="2-1视觉感知"><a href="#2-1视觉感知" class="headerlink" title="2.1视觉感知"></a>2.1视觉感知</h2><p>眼睛构造；晶状体成像；</p>
<p>人的视觉模型：低通滤波-log-高通滤波</p>
<p>视觉特性：二者说明感觉亮度不是一维简单函数</p>
<ul>
<li>同时对比度：相对的明暗强度感受</li>
<li>mach带效应：在明暗变化部位附近，暗区/亮区存在一条更暗/亮的条带</li>
</ul>
<p>$$<br>S=KlnI+K_0<br>$$</p>
<p>人的感觉量与刺激量的对数成正比，在光弱时对变化敏感，在光强时对变化不敏感。</p>
<p>视觉时间特性：视觉暂留效应、形状感觉、错视</p>
<h2 id="2-2色度学基础"><a href="#2-2色度学基础" class="headerlink" title="2.2色度学基础"></a>2.2色度学基础</h2><p>RGB模型：三维空间中的一个点表示颜色</p>
<img src="/2022/11/30/ImageProc/image-20221202145928763.png" class="" title="image-20221202145928763"><img src="/2022/11/30/ImageProc/image-20221202145952850.png" class="" title="image-20221202145952850">

<p>玩不腻是吧</p>
<p>HSI：色调、饱和度、强度模型</p>
<img src="/2022/11/30/ImageProc/image-20221202150035781.png" class="" title="image-20221202150035781">

<h2 id="2-3图像的数字化"><a href="#2-3图像的数字化" class="headerlink" title="2.3图像的数字化"></a>2.3图像的数字化</h2><h3 id="1采样"><a href="#1采样" class="headerlink" title="1采样"></a>1采样</h3><p>将在时间和空间上连续的图像转化成离散的采样点集（即像素）的操作</p>
<p>静止图像，分别沿垂直+水平采样；运动图像（时间域连续），需现在时间轴上采样，再进行静止图像类似操作。</p>
<p>采样两个参数：采样间隔，采样孔径</p>
<p>香农采样定理（一维采样定理）：采样的频率&gt;=原始频率的两倍，就可以完全精确地复原原来的连续信息</p>
<p>均匀采样：等间隔采样</p>
<p>非均匀采样：根据图像细节的丰富程度改变采样间距</p>
<h3 id="2量化"><a href="#2量化" class="headerlink" title="2量化"></a>2量化</h3><p>将像素灰度转换为离散的整数值的过程。</p>
<p>一般用0-255表示256个灰度级</p>
<p>一般使用等间隔矩形网络采样，对幅度进行等间隔量化。</p>
<p>均匀量化</p>
<p>非均匀量化：对像素出现频度少的部分量化间隔取大，频度大的部分量化间隔取小。</p>
<h3 id="3块状和假轮廓现象"><a href="#3块状和假轮廓现象" class="headerlink" title="3块状和假轮廓现象"></a>3块状和假轮廓现象</h3><ul>
<li><p>对一幅图像，当量化级数<em>Q</em>一定时，采样点数越多，图像质量越好；当采样点数减少时，图上的块状效应就逐渐明显。</p>
<img src="/2022/11/30/ImageProc/image-20221202152221624.png" class="" title="image-20221202152221624"></li>
<li><p>当图像的采样点数一定时量化级数越多，图像质量越好；当量化级数越少时，图像质量越差，量化级数最小的极端情况就是二值图像， 图像出现假轮廓。如下图所示</p>
<img src="/2022/11/30/ImageProc/image-20221202152310504.png" class="" title="image-20221202152310504">

<p>256色-64-32-16-4-2二值图像</p>
</li>
</ul>
<p>（1）对缓变的图像，应该细量化，粗采样，以避免假轮廓。</p>
<p>（2）对细节丰富的图像，应细采样，粗量化，以避免模糊（混叠）。</p>
<h2 id="2-4数字图像的数值描述"><a href="#2-4数字图像的数值描述" class="headerlink" title="2.4数字图像的数值描述"></a>2.4数字图像的数值描述</h2><p>有点乱</p>
<p>编程方便，使用矩阵坐标系定义图像的坐标。</p>
<h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><ul>
<li>黑白图像/二值图像</li>
<li>灰度图像</li>
<li>彩色图像</li>
</ul>
<h3 id="图像质量"><a href="#图像质量" class="headerlink" title="图像质量"></a>图像质量</h3><ul>
<li>层次：表示灰度级的数量，层次越多视觉效果越好</li>
<li>对比度：亮度（灰度，明暗变化）的局部变化，画面黑、白的反差/渐变层次，比值越大层次越多图像越丰富。对比度=最大亮度/最小亮度</li>
<li>清晰度：相关因素有亮度、对比度、主题内容大小、细微层次、颜色饱和度</li>
</ul>
<h2 id="2-5数字图像的数据结构"><a href="#2-5数字图像的数据结构" class="headerlink" title="2.5数字图像的数据结构"></a>2.5数字图像的数据结构</h2><p>二维数组、组合方式、比特面、分层结构、树状结构</p>
<h2 id="2-6像素间的基本关系"><a href="#2-6像素间的基本关系" class="headerlink" title="2.6像素间的基本关系"></a>2.6像素间的基本关系</h2><p>4邻域、对角邻域、8邻域</p>
<h3 id="像素连通性"><a href="#像素连通性" class="headerlink" title="像素连通性"></a>像素连通性</h3><p>定义V是用于定义邻接性的灰度值集合，存在三种类型的邻接性：</p>
<p>(1)4邻接:如果q在N4(p)集中,具有V中数值的两个像素p和q是4邻接的.</p>
<p>(2)8邻接:如果q在N8(p)集中,具有V中数值的两个像素p和q是8邻接的.</p>
<p>(3)m邻接(混合邻接):如果</p>
<p>   (i)q在N4(p)中 或</p>
<p>   (ii)q在ND(p)中且集合N4(p)∩N4(q)没有V值的像素.</p>
<p>m邻接可以消除8邻接所带来的二义性，实质是当同时存在4邻接和8邻接时，优先采用4邻接。</p>
<h3 id="像素通路"><a href="#像素通路" class="headerlink" title="像素通路"></a>像素通路</h3><p>像素点<em>p</em>(<em>x</em>, <em>y</em>)到像素点<em>q</em>(<em>s</em>, <em>t</em>)的通路(path):</p>
<p>特定的像素序列(<em>x</em>0,<em>y</em>0),(<em>x</em>1,<em>y</em>1),…,(<em>xn</em>,<em>yn</em>),其中(<em>x</em>0,<em>y</em>0)=<em>p</em>(<em>x</em>,<em>y</em>), (<em>xn</em>,<em>yn</em>)=<em>q</em>(<em>s</em>,<em>t</em>), 且像素(<em>xi</em>, <em>yi</em>)和(<em>xi</em>-1, <em>yi</em>-1) (对于1≤<em>i</em>≤<em>n</em>)是邻接的.</p>
<p><em>n</em>是通路的长度。</p>
<p>若(<em>x</em>0, <em>y</em>0)=(<em>xn</em>, <em>yn</em>),则通路是闭合通路。</p>
<img src="/2022/11/30/ImageProc/image-20221202154814811.png" class="" title="image-20221202154814811">



<h2 id="2-7数字图像处理的基本方法"><a href="#2-7数字图像处理的基本方法" class="headerlink" title="2.7数字图像处理的基本方法"></a>2.7数字图像处理的基本方法</h2><p>1局部运算</p>
<ul>
<li>点运算</li>
<li>邻域运算</li>
</ul>
<p>2迭代运算</p>
<p>3位置不变处理和位置可变处理</p>
<p>4窗口运算和模版运算：窗口划定了一个矩形区域，模板是一个特定形状区域</p>
<p>5帧运算：在两幅或多幅图像间进行运算产生一幅新图像的处理。</p>
<h1 id="Chapter3-位图图像基础"><a href="#Chapter3-位图图像基础" class="headerlink" title="Chapter3.位图图像基础"></a>Chapter3.位图图像基础</h1><h2 id="3-1位图文件"><a href="#3-1位图文件" class="headerlink" title="3.1位图文件"></a>3.1位图文件</h2><h3 id="数字图像类型"><a href="#数字图像类型" class="headerlink" title="数字图像类型"></a>数字图像类型</h3><h4 id="矢量图"><a href="#矢量图" class="headerlink" title="矢量图"></a>矢量图</h4><p>是用一系列绘图指令来表示一幅图，如AutoCAD中的绘图语句。这种方法的本质是用数学(更准确地说是几何学)公式描述一幅图像。图像中每一个形状都是一个完整的公式，称为一个对象。对象是一个封闭的整体，所以图像上对象的变化都不会影响到图像中的其他对象。实质就是用数学公式描述的图像就是矢量图。</p>
<p>矢量图的特点：</p>
<p>  矢量图的两个优点：</p>
<p>一是它的文件数据量很小；</p>
<p>二是<strong>图像质量与分辨率无关</strong>，不会失真，这意味着无论将图像放大或缩小了多少次，图像总是以显示设备允许的最大清晰度显示。</p>
<p>  矢量图有一个明显的缺点，就是不易制作色调丰富或色彩变化太多的图像，而且绘出来的图像不是很逼真，同时也不易在不同的软件间交换文件。</p>
<p>在Corel Draw和Adobe Illustrator中生成的图像均为矢量图 。</p>
<h4 id="位图-BMP位图"><a href="#位图-BMP位图" class="headerlink" title="位图-BMP位图"></a>位图-BMP位图</h4><p>是由像素点构成一幅图像，每个像素点具有颜色属性和位置属性。放大会产生失真</p>
<p>Windows把位图分为两类：设备无关位图DIB，设备相关位图DDB</p>
<p>DDB位图没有调色板，其数据结构与设备有关的，显示的颜色依赖硬件；DIB位图自带颜色信息即调色板。</p>
<p>线画稿：黑白2色，0,1</p>
<p>灰度图像：0-255</p>
<p>索引颜色图像：使用预先定义的调色板色表的图像，最多只能显示256色</p>
<p>真彩色图像：RGB 24bit</p>
<h2 id="3-2位图文件结构"><a href="#3-2位图文件结构" class="headerlink" title="3.2位图文件结构"></a>3.2位图文件结构</h2><p>位图文件=文件头+位图信息（=位图信息头+调色板）+位图像素数据</p>
<p>位图文件头作用：是设定图像文件类型，大小等。</p>
<p>位图信息作用：所记录的值用于分配内存，设置调色板信息，读取像素值等。</p>
<img src="/2022/11/30/ImageProc/image-20221202160748873.png" class="" title="image-20221202160748873">

<p>位图文件头：14B</p>
<img src="/2022/11/30/ImageProc/image-20221202161501334.png" class="" title="image-20221202161501334">

<p>位图信息头：40B</p>
<img src="/2022/11/30/ImageProc/image-20221202161653920.png" class="" title="image-20221202161653920">

<p>调色板：一个数组，对需要调色板的位图文件而言的，如果是真彩色图像，则位图信息头后面直接是位图数据。</p>
<p>位图数据：在DIB中，图像的<strong>底行是文件的第一行</strong>，图像的<strong>顶行是文件的最后一行</strong>。</p>
<ul>
<li> 对于用到调色板的位图，图像数据就是该像素颜色在调色板中的索引值。</li>
<li> 对于真彩色图像，图像数据就是实际的R、 G、 B值。图像数据中每3个字节表示一个像素，每个字节表示一个RGB分量</li>
<li> 对于2色位图，用1位就可以表示该像素的颜色（一般0表示黑， 1表示白），所以一个字节可以表示8个像素。</li>
<li> 对于16色位图，用4位可以表示一个像素的颜色，所以一个字节可以表示2个像素。</li>
<li> 对于256色位图，一个字节刚好可以表示1个像素。</li>
</ul>
<img src="/2022/11/30/ImageProc/image-20221202162152753.png" class="" title="image-20221202162152753">

<p>还要倒读？！</p>
<p>小端方式存储数据，低地址存放低位数据</p>
<p>如0x1756实际存储是(small address)56 17(big add)</p>
<img src="/2022/11/30/ImageProc/image-20221202162740177.png" class="" title="image-20221202162740177">

<img src="/2022/11/30/ImageProc/D9E3DBE91C926806BE7E4B8427FB91DD.png" class="" title="img">

<p>后面的不会考吧不会吧不写了</p>
<h1 id="Chapter4-图像的几何变换"><a href="#Chapter4-图像的几何变换" class="headerlink" title="Chapter4.图像的几何变换"></a>Chapter4.图像的几何变换</h1><h2 id="4-1几何变换基础"><a href="#4-1几何变换基础" class="headerlink" title="4.1几何变换基础"></a>4.1几何变换基础</h2><p>1 图像的几何变换：是指用数学建模的方法来描述图像的位置，大小，形状等变换的方法，也就是通过数学建模实现对数字图像进行几何变换处理。</p>
<p>2 几何变换内容：图像的空间平移、比例缩放、旋转、仿射变换和图像插值。</p>
<p>3 几何变换实质：改变像素的空间位置或估算新空间位置上的像素值。</p>
<p>齐次坐标什么的</p>
<p>所谓齐次坐标表示法就是用N+1维向量表示N维向量。线性代数</p>
<h2 id="4-2图像的位置变换"><a href="#4-2图像的位置变换" class="headerlink" title="4.2图像的位置变换"></a>4.2图像的位置变换</h2><h3 id="平移"><a href="#平移" class="headerlink" title="平移"></a>平移</h3><p>平移原理：在图像平移是将一幅图像中所有的点都按照指定的平移量在水平、垂直方向移动，平移后的图像与原图像相同。</p>
<img src="/2022/11/30/ImageProc/image-20221202202600583.png" class="" title="image-20221202202600583">

<img src="/2022/11/30/ImageProc/image-20221202203011029.png" class="" title="image-20221202203011029">

<p>平移的直角坐标公式：图像的平移用到的是中学学过的直角坐标系的平移变换公式：    </p>
<img src="/2022/11/30/ImageProc/image-20221203100111747.png" class="" title="image-20221203100111747">

<p>平移的逆变换：对变换矩阵求逆，可以得到逆变换 </p>
<img src="/2022/11/30/ImageProc/image-20221203100122516.png" class="" title="image-20221203100122516">

<p>逆变换作用：平移后的图像上的每一点通过逆变换在原图像中找到对应的点，则平移后的图象中每个象素的颜色利用逆变换确定。按照逆变换公式得到的(<em>x</em>0,<em>y</em>0)不在原图中该怎么办？即逆变换往往得到的点不在原图中。 通常的做法是，把该点的RGB值统一设成(0,0,0)或者(255,255,255)。</p>
<h3 id="镜像"><a href="#镜像" class="headerlink" title="镜像"></a>镜像</h3><p>镜像分为水平镜像和垂直镜像。</p>
<p>水平镜像：以图像的垂直中轴线为中心交换图像的左右 两部分。设图像高度为Height，宽度为Width，原图中的(x0,y0)经过水平镜像后，坐标将变成（Width-x0,y0）。</p>
<img src="/2022/11/30/ImageProc/image-20221202205021669.png" class="" title="image-20221202205021669">

<p>垂直镜像：以图像的水平中轴线为中心交换图像的上下两部分。点（x0,y0）经过垂直镜像后，坐标将变成为（x0,Height-y0）</p>
<img src="/2022/11/30/ImageProc/image-20221202205042731.png" class="" title="image-20221202205042731">

<img src="/2022/11/30/ImageProc/image-20221202204810249.png" class="" title="image-20221202204810249">

<h3 id="旋转"><a href="#旋转" class="headerlink" title="旋转"></a>旋转</h3><p>图像的旋转是指以图像中的<strong>某一点</strong>（一般是中心点）为原点以逆时针或顺时针的方向旋转一定的角度。旋转后，图像的大小一般会改变。</p>
<h4 id="直角坐标系图像旋转"><a href="#直角坐标系图像旋转" class="headerlink" title="直角坐标系图像旋转"></a>直角坐标系图像旋转</h4><img src="/2022/11/30/ImageProc/image-20221203093351466.png" class="" title="image-20221203093351466">

<p>这个计算公式计算出的值为小数，而坐标值为正整数。</p>
<p>这个计算公式计算的结果值所在范围与原来的值所在的范围不同。</p>
<p>因此需要前期处理 ：扩大画布，取整处理（解决小数问题），平移处理（解决负数问题）</p>
<p>注意theta是逆时针转角</p>
<p>一些问题：小数，负数，图像转飞，空洞</p>
<img src="/2022/11/30/ImageProc/image-20221203093950723.png" class="" title="image-20221203093950723">

<img src="/2022/11/30/ImageProc/image-20221203093959994.png" class="" title="image-20221203093959994">

<img src="/2022/11/30/ImageProc/image-20221203094009267.png" class="" title="image-20221203094009267">

<p>图像旋转之后，像素排列的两个问题：</p>
<p>1）像素的排列不是完全按照原有的相邻关系。这是因为相邻像素之间只能有8个方向方向不够细腻。即转飞</p>
<p>2）会出现许多的空洞点。即出现空白点</p>
<p>这个最好算一下捏</p>
<img src="/2022/11/30/ImageProc/image-20221203094433237.png" class="" title="image-20221203094433237">

<img src="/2022/11/30/ImageProc/image-20221203094607509.png" class="" title="image-20221203094607509">

<p>图像旋转出现的两个问题的 本质 都是因为像素值的填充是不连续的离散不连续造成。</p>
<p>因此可以采用插值填充的方法来解决。   </p>
<p>插值填充法：临近插值法，均值插值法。</p>
<p>临近插值法：就是将判断为空穴位置上的像素值用其相邻行（或列）的像素值来填充。</p>
<p>均值插值法：是将空穴像素周围像素值的均值填充。</p>
<h4 id="极坐标旋转"><a href="#极坐标旋转" class="headerlink" title="极坐标旋转"></a>极坐标旋转</h4><p>利用极坐标中的角度，直接做旋转，然后再转换为对应的直角坐标</p>
<p>先转换为极坐标-极坐标旋转-逆变换为直角坐标</p>
<img src="/2022/11/30/ImageProc/image-20221203095041008.png" class="" title="image-20221203095041008"><img src="/2022/11/30/ImageProc/image-20221203095045907.png" class="" title="image-20221203095045907">

<img src="/2022/11/30/ImageProc/image-20221203095103364.png" class="" title="image-20221203095103364">

<p>先将横纵坐标代入直角转极坐标公式算出p和theta，旋转后只改变theta，p不变</p>
<img src="/2022/11/30/ImageProc/image-20221203095912063.png" class="" title="image-20221203095912063">

<h4 id="反变换旋转"><a href="#反变换旋转" class="headerlink" title="反变换旋转"></a>反变换旋转</h4><p>没有空穴，但是仍存在转飞</p>
<p>基本原理：就是从新图像的像素点坐标反过来求其所对应的原图像的像素点的坐标。</p>
<img src="/2022/11/30/ImageProc/image-20221203100209329.png" class="" title="image-20221203100209329">

<p>步骤：先确定画布大小-确定新图像坐标-计算出对应的原图像坐标。</p>
<ol>
<li><p>确定原图旋转30°后的画布大小，这点我们可从坐标旋转公式计算得到。x[-1,2],y[1,4]。因此，变换后的画布大小是4×4</p>
</li>
<li><p>规范前的新图像的坐标x’  y’</p>
</li>
</ol>
<img src="/2022/11/30/ImageProc/image-20221203100449130.png" class="" title="image-20221203100449130">

<ol start="3">
<li>根据反变换公式，得到其对应的原图像F的行,列坐标:新图像中像素（0，2）对应的原图像中像素（1，2）.因为把像素（0，2）代入反变换公式得到：四舍五入</li>
</ol>
<p>​         x=2*sin30=1</p>
<p>​         y=1.732=2</p>
<img src="/2022/11/30/ImageProc/image-20221203100635423.png" class="" title="image-20221203100635423">

<ol start="4">
<li>旋转后新图像为</li>
</ol>
<p>G=0  0  f13  0</p>
<p>   f11 f12 f13  f23</p>
<p>​    0  f21 f22  f33</p>
<p>​    0  f31 f32  0</p>
<p>可以看出，新图像G(0.2)像素点放的是原图像F(1，2)像素点，反变换法没有空穴，因此不需要后续的插值处理。</p>
<h2 id="4-3图像的形状变换"><a href="#4-3图像的形状变换" class="headerlink" title="4.3图像的形状变换"></a>4.3图像的形状变换</h2><h3 id="图像缩小"><a href="#图像缩小" class="headerlink" title="图像缩小"></a>图像缩小</h3><p>分为按比例缩小和不按比例缩小两种。图像缩小之后，因为承载的信息量小了，所以画布可相应缩小</p>
<p>图像缩小：实际上就是对原有的多个数据进行挑选或处理。</p>
<p>原理：获得期望缩小尺寸的数据，并且尽量保持原有的特征不丢失。</p>
<p>方法：最简单的方法就是等间隔地选取数据。相当于采样 </p>
<img src="/2022/11/30/ImageProc/image-20221203101257496.png" class="" title="image-20221203101257496">

<p>反变换思想：</p>
<img src="/2022/11/30/ImageProc/68646DC046C22A4FB591364787036A09.png" class="" title="img">

<h3 id="放大"><a href="#放大" class="headerlink" title="放大"></a>放大</h3><p>图像放大算法关键：在于对未知像素使用何种插值方式。</p>
<p>放大原理：如果需要将原图像放大k倍，则将原图像中的每个像素值，填在新图像中对应的k*k大小的子块中。</p>
<img src="/2022/11/30/ImageProc/image-20221203102324216.png" class="" title="image-20221203102324216">

<h4 id="普通放大"><a href="#普通放大" class="headerlink" title="普通放大"></a>普通放大</h4><p>设原图像大小为M<em>N,放大为k1M</em>k2N，<strong>（k1&gt;1，k2&gt;1）</strong>。算法步骤如下：</p>
<ol>
<li><p>设旧图像是F(i,j)， i=1,2,…,M, j=1,2,…,N。新图像是I(x,y), x=1,2,…,k1M, y=1,2,…,k2N。</p>
</li>
<li><p>I(x,y)=F(c1<em>x, c2</em>y), 新图的点与原图的点的对应计算，都是要找在原图中的对应位置。原图相当于是新图缩小c1=1/k1     c2=1/k2</p>
</li>
</ol>
<h4 id="最邻近点插值"><a href="#最邻近点插值" class="headerlink" title="最邻近点插值"></a>最邻近点插值</h4><p>最邻近点插值算法是最简单也是速度最快的一种算法，其做法是将放大后未知的像素点P，將其位置换算到原始影像上，与原始的邻近的4周像素点A,B,C,D做比较，令P点的像素值等于最靠近的邻近点像素值即可。如上图中的P点，由于最接近D点，所以就直接取P=D</p>
<p>这种方法会带来明显的失真。在A, B中点处的像素值会突然出现一个跳跃，这就是出现马赛克和锯齿等明显走样的原因。最临近插值法唯一的优点就是速度快。</p>
<img src="/2022/11/30/ImageProc/image-20221203102844840.png" class="" title="image-20221203102844840">



<h4 id="双线性插值"><a href="#双线性插值" class="headerlink" title="双线性插值"></a>双线性插值</h4><img src="/2022/11/30/ImageProc/image-20221203102948346.png" class="" title="image-20221203102948346">

<ol>
<li>假设A图像的灰度级变化在纵向方向上是<strong>线性变化</strong>的，这样根据直线方程或者几何比例关系就能够求得(a,y/4)和(a+1,y/4)坐标处的灰度级A(a,y/4)和A’(a+1,y/4)。</li>
<li>再假设在((a,y/4),A(a,y/4))和(a+1,y/4),A’(a+1,y/4)这两点所确定的直线上，灰度级仍然是线性变化的。求出直线方程，于是就可以求得(x/4,y/4)处的灰度级A(x/4,y/4)。</li>
</ol>
<p>算法</p>
<ol>
<li><p>先按照基于像素放大原理就是最邻近像素点法的图像放大方法，确定每一个原图像的像素在新图像中对应的子块。对新图像中每一个子块，仅对其一个像素进行填充。在每个子块中选取一个填充像素的方法如下：</p>
<p> 对右下角的子块，选取子块中右下角的像素；</p>
<p> 对末列、非末行子块，选取子块中的右上角像素；</p>
<p> 对末行、非末列子块，选取子块中的左下角像素；</p>
<p> 对剩余的子块，选取子块中的左上角像素。</p>
<img src="/2022/11/30/ImageProc/image-20221203105205370.png" class="" title="image-20221203105205370">

<img src="/2022/11/30/ImageProc/image-20221203105200644.png" class="" title="image-20221203105200644"></li>
<li><p>计算已填充像素所在列中的其他像素的值，根据该像素上方与下方已填充的像素值，双线性插值方法得到</p>
<img src="/2022/11/30/ImageProc/image-20221203105533650.png" class="" title="image-20221203105533650"></li>
<li><p>对剩余像素的值，可以利用该像素的左方与右方的已填充像素的值，通过线性插值方法计算得到。 </p>
<img src="/2022/11/30/ImageProc/image-20221203105633794.png" class="" title="image-20221203105633794"></li>
</ol>
<h2 id="4-4图像错切"><a href="#4-4图像错切" class="headerlink" title="4.4图像错切"></a>4.4图像错切</h2><p>错切：图像的错切变换实际上是平面景物在投影平面上的非垂直投影效果。错切变换也称为剪切、错位或错移变换。</p>
<p>原理：保持图像上各点的某一坐标值不变，而另一坐标值进行线性变换。坐标不变的轴称为依赖轴，变换的轴称为方向轴。</p>
<p>因为绝大多数图像都是三维物体在二维平面上的投影得到的，所以需要研究图像的错切现象。</p>
<p>沿x轴关于y的错切：变换前和变换后y值坐标保持不变，而x坐标依赖于初始坐标值(x,y)及参数c的值呈线性变化。</p>
<img src="/2022/11/30/ImageProc/image-20221203105805173.png" class="" title="image-20221203105805173"><img src="/2022/11/30/ImageProc/image-20221203110030978.png" class="" title="image-20221203110030978">

<p>沿y轴关于x错切同理。变换前和变换后x值坐标保持不变，而y坐标与初始坐标值（x,y）及参数b有关。</p>
<img src="/2022/11/30/ImageProc/image-20221203110134896.png" class="" title="image-20221203110134896"><img src="/2022/11/30/ImageProc/image-20221203110143323.png" class="" title="image-20221203110143323">

<p>错切之后原图像的像素排列方向发生改变。与旋转不同的是，x方向与y方向独立变化。</p>
<img src="/2022/11/30/ImageProc/image-20221203110211986.png" class="" title="image-20221203110211986">



<h2 id="4-5三维图像的投影变换"><a href="#4-5三维图像的投影变换" class="headerlink" title="4.5三维图像的投影变换"></a>4.5三维图像的投影变换</h2><p>似乎比较复杂然后没有细讲？ppt干干净净</p>
<img src="/2022/11/30/ImageProc/image-20221203110245059.png" class="" title="image-20221203110245059">

<h1 id="Chapter5-图像的灰度变换"><a href="#Chapter5-图像的灰度变换" class="headerlink" title="Chapter5.图像的灰度变换"></a>Chapter5.图像的灰度变换</h1><h2 id="5-1图像增强处理技术"><a href="#5-1图像增强处理技术" class="headerlink" title="5.1图像增强处理技术"></a>5.1图像增强处理技术</h2><p>是指按特定的需要突出一幅图像中的某些信息。同时，削弱或去除某些不需要的信息的处理方法。</p>
<p>图像在传输或处理过程中会引入噪声或使图像变模糊，从而降低了图像质量，甚至淹没了特征，给分析带来困难，因此要增强特征，进行处理。</p>
<p>在图像增强的过程中，没有新信息的增加，只是通过压制一部分信息，从而突出另一部分信息。也就是说，增强处理并不能增强原始图像的信息，其结果只能增强某种信息的辨识能力，而这种处理有可能损失一些其他信息。</p>
<p>分类：</p>
<ol>
<li>频域处理方法，基础是卷积定理，采用修改图像傅立叶变换的方法实现对图像的增强。常用的方法，低通滤波，高频提升滤波、同态滤波等。</li>
<li>空域处理方法，直接对图像中的像素灰度进行处理，基本上是以灰度映射变换为基础。所用的映射变换取决于增强的目的。包括灰度变换、直方图修正，平滑和锐化处理、彩色增强等。</li>
</ol>
<h2 id="5-2灰度变换"><a href="#5-2灰度变换" class="headerlink" title="5.2灰度变换"></a>5.2灰度变换</h2><h3 id="灰度直方图"><a href="#灰度直方图" class="headerlink" title="灰度直方图"></a>灰度直方图</h3><p>概念：灰度直方图是灰度级的函数，是对图像中灰度级分布的统计。反映的是一幅图像中各灰度级像素出项的频率。灰度直方图就是频率同灰度级的关系图。</p>
<p>形式：横坐标表示<strong>灰度级</strong>，纵坐标表示图像中对应<strong>某灰度级所出现的像素个数</strong>，也可以是某一灰度值的像素数占全图像素数的百分比，即灰度级的频率（也是直方图归一化）。</p>
<p>功能：它是图像的一个重要特征，反映了图像<strong>灰度分布</strong>的情况。灰度直方图是最简单且最有用的工具。</p>
<img src="/2022/11/30/ImageProc/image-20221203112315615.png" class="" title="image-20221203112315615">

<p>性质：</p>
<ul>
<li><p>灰度直方图只能反映图像的灰度分布，而不能反映图像像素的位置，即丢失了像素的<strong>位置</strong>信息。</p>
</li>
<li><p>一幅图像对应唯一的灰度直方图，反之不成立。不同的图像可对应相同的直方图，下图给出了一个不同的图像具有相同直方图的例子。同样也是丢失位置信息</p>
<img src="/2022/11/30/ImageProc/image-20221203112418137.png" class="" title="image-20221203112418137"></li>
<li><p>一幅图像分成多个区域，多个区域的直方图之和即为原图像的直方图。</p>
</li>
</ul>
<h3 id="对比度计算"><a href="#对比度计算" class="headerlink" title="对比度计算"></a>对比度计算</h3><p>亮度（灰度，明暗变化）的局部变化，画面黑、白的反差/渐变层次，比值越大层次越多图像越丰富。</p>
<p>对比度=最大亮度/最小亮度，计算公式：（？？）相邻像素：可选4邻域，8邻域两种</p>
<img src="/2022/11/30/ImageProc/image-20221203113051738.png" class="" title="image-20221203113051738">

<p>计算例：中心像素灰度值与周围4近邻像素灰度值之差的平方之和，除以以上平方项的个数。</p>
<img src="/2022/11/30/ImageProc/image-20221203113234560.png" class="" title="image-20221203113234560">

<p>从(1,1)点开始，范围之外的坐标点不进行计算；因此第一项只有下面的(2,1)，右边的(1,2)两点</p>
<h3 id="线性灰度变换"><a href="#线性灰度变换" class="headerlink" title="线性灰度变换"></a>线性灰度变换</h3><img src="/2022/11/30/ImageProc/image-20221203113953945.png" class="" title="image-20221203113953945">

<p>线性变换：正比和反比</p>
<p>非线性：对数、幂</p>
<p>在曝光不足或过度的情况下，图像灰度可能会局限在一个很小的范围内。这时就形成一个模糊不清，似乎没有灰度层次的图像。采用线性变换对图像每一个像素灰度做线性拉伸，可有效地改善图像视觉效果。</p>
<img src="/2022/11/30/ImageProc/image-20221203114439459.png" class="" title="image-20221203114439459">

<h4 id="分段线性变换"><a href="#分段线性变换" class="headerlink" title="分段线性变换"></a>分段线性变换</h4><p>1扩展感兴趣的，牺牲其他</p>
<p>对于感兴趣的[a,b]区间，采用斜率大于1的线性变换来进行扩展，而把其他区间用a或b来表示。变换函数是</p>
<img src="/2022/11/30/ImageProc/image-20221203114542984.png" class="" title="image-20221203114542984">

<p>2扩展感兴趣的，压缩其他</p>
<p>在扩展感兴趣的[a,b]区间的同时，为了保留其他区间的灰度层次，也可以采用其它区间压缩的方法，既有扩有压，变换函数为</p>
<img src="/2022/11/30/ImageProc/image-20221203114559242.png" class="" title="image-20221203114559242">

<img src="/2022/11/30/ImageProc/image-20221203114603972.png" class="" title="image-20221203114603972">

<p>一些应用：</p>
<h5 id="对比度线性展宽（拉伸）"><a href="#对比度线性展宽（拉伸）" class="headerlink" title="对比度线性展宽（拉伸）"></a>对比度线性展宽（拉伸）</h5><p>目的：通过将亮暗差异（即对比度）扩大，来把人所关心的部分强调出来。</p>
<p>原理：进行像素点对点的，灰度级的线性影射。该影射关系通过调整参数，来实现对亮暗差异的扩大。</p>
<p>对比度展宽的特性：处理前后的图像量化级数相同，即处理前后图像的灰度分布范围都是[0，255]，但处理后的图像的表现效果要优于处理前的图像。</p>
<p>进行对比度展宽，只能通过抑制非重要信息的对比度来腾出空间给重要信息进行对比图展宽。</p>
<p>对比度线性展宽原理：实际就是图像灰度值的线性映射。进行像素点对点的，灰度级的影射。</p>
<p>对比度线性展宽处理方法：按照下面的公式进行点对点的映射</p>
<img src="/2022/11/30/ImageProc/image-20221203115638585.png" class="" title="image-20221203115638585">

<p>对比度展宽（拉伸）例图。</p>
<p>(a)变换函数的形式(b)低对比度图像</p>
<p>(c)对比度展宽（拉伸）的结果(d)门限化的结果</p>
<img src="/2022/11/30/ImageProc/image-20221203161717799.png" class="" title="image-20221203161717799">

<h5 id="灰窗级"><a href="#灰窗级" class="headerlink" title="灰窗级"></a>灰窗级</h5><p>当256个灰度级所表示的亮暗范围内的信息量太大，没办法很好地表述时，通过开窗的方式，只把窗内的灰度级展宽，而把窗外的灰度级完全抑制掉。</p>
<p>什么是灰窗级?就是通过映射关系，把灰度值落在一定范围内的目标进行对比度增强。也就是只显示指定灰度范围内的信息。</p>
<p>灰窗级实际上是线性对比度展宽的一种特殊形式。</p>
<img src="ImageProc/image-20221203161923980.png" alt="image-20221203161923980" style="zoom: 67%;" />

<h5 id="灰窗级切片（灰度切割）"><a href="#灰窗级切片（灰度切割）" class="headerlink" title="灰窗级切片（灰度切割）"></a>灰窗级切片（灰度切割）</h5><p>1 什么是灰窗级切片?</p>
<p>  是指将所需检测的目标与画面中其他的部分分离开，目标部分置为白（黑），而非目标部分置为黑（白）。这样就把需要的目标突显出来，消除背景细节。</p>
<p>2 灰窗级切片有什么用？</p>
<p>  在图像处理中，经常要对某个目标物的形状、边界、截面面积以及体积进行测量，从而得到该目标物功能方面的重要信息。如，医学中要对人体器官和组织进行精确测量。</p>
<p><img src="ImageProc/image-20221203162316469.png" alt="image-20221203162316469" style="zoom:50%;" /><img src="ImageProc/image-20221203162233579.png" alt="image-20221203162233579" style="zoom:50%;" /></p>
<h5 id="线性动态范围调整（效果同灰窗级）"><a href="#线性动态范围调整（效果同灰窗级）" class="headerlink" title="线性动态范围调整（效果同灰窗级）"></a>线性动态范围调整（效果同灰窗级）</h5><p>动态范围：是指图像中从暗到亮的变化范围。变换后图像的0-255并不是原图像的0-255</p>
<p>动态范围对人视觉的影响：由于人眼所可以分辨的灰度的变化范围是有限的，所以当动态范围太大时，很高的亮度值把暗区的信号都掩盖了。</p>
<p>动态范围调整思路：通过动态范围的压缩可以将所关心部分的灰度级的变化范围扩大。</p>
<p>动态范围调整方法分为以下两种：</p>
<p>1）线性动态范围调整</p>
<p>2）非线性动态范围调整</p>
<p>线性动态范围调整的基本思路：通过把原图中“不太黑”的像素也变成黑，把原图中“不太白”的相素也变成白的方式，来压缩动态范围，使新的图像中，关心部分的对比度可以展宽。</p>
<p>如下图所示，将原来[0,255]范围内的亮暗变化，压缩到[a,b]范围内。再将[a,b]范围内的灰度值扩张到[0,255]。</p>
<img src="/2022/11/30/ImageProc/image-20221203162545318.png" class="" title="image-20221203162545318">

<img src="/2022/11/30/ImageProc/image-20221203163112941.png" class="" title="image-20221203163112941">



<h3 id="非线性灰度变换"><a href="#非线性灰度变换" class="headerlink" title="非线性灰度变换"></a>非线性灰度变换</h3><h4 id="对数变换"><a href="#对数变换" class="headerlink" title="对数变换"></a>对数变换</h4><img src="/2022/11/30/ImageProc/image-20221203163200300.png" class="" title="image-20221203163200300">

<p>其中 lambda是调节常数。用于调节变换后的灰度值，使其符合实际要求。</p>
<p>对数变换的作用是扩展图像的低灰度范围，同时压缩高灰度范围。</p>
<img src="/2022/11/30/ImageProc/image-20221203163618169.png" class="" title="image-20221203163618169">

<h4 id="幂次变换"><a href="#幂次变换" class="headerlink" title="幂次变换"></a>幂次变换</h4><p>和对数变换的效果相反，指数变换使得高灰度范围扩展，压缩低灰度范围</p>
<img src="/2022/11/30/ImageProc/image-20221203163753051.png" class="" title="image-20221203163753051">

<p>其中c和gamma为常数。 gamma值的选择对于变换函数的特性有很大影响，如下图示。</p>
<img src="/2022/11/30/ImageProc/image-20221203163833322.png" class="" title="image-20221203163833322">

<img src="/2022/11/30/ImageProc/image-20221203163838970.png" class="" title="image-20221203163838970">

<p>应用：γ校正</p>
<p>几乎所有的CRT显示设备、摄像胶片、许多电子照相机的光电转换特性都是非线性的。所以，如果不进行校正处理的话，将无法得到好的图像效果。</p>
<p>l光电传感器的输入输出特性：这些非线性部件的输出与输入之间的关系可以用一个幂函数来表示，形式为：设CCD的输入（入射光强度）为L，输出（电流强度）为I，则有：</p>
<img src="ImageProc/image-20221203164055132.png" alt="image-20221203164055132" style="zoom:50%;" />

<p>1.在显示之前通过幂次变换将图像进行修正。</p>
<img src="ImageProc/image-20221203164129879.png" alt="image-20221203164129879" style="zoom:50%;" />

<p>通常CCD的γ值在0.4 ~ 0.8之间，γ值越小，画面的效果越差。根据画面对比度的观察与分析，可以大致得到该设备的γ值（或依据设备的参考γ值）</p>
<img src="/2022/11/30/ImageProc/image-20221203164539689.png" class="" title="image-20221203164539689">

<p>2.对输入信息进行γ校正</p>
<img src="ImageProc/image-20221203164801845.png" alt="image-20221203164801845" style="zoom:50%;" />

<img src="/2022/11/30/ImageProc/image-20221203164813596.png" class="" title="image-20221203164813596">

<h3 id="代数运算"><a href="#代数运算" class="headerlink" title="代数运算"></a>代数运算</h3><p>算术运算常用于灰度图像。逻辑运算用于二值图像。</p>
<p>加，减，乘，除</p>
<p>与或非，异或</p>
<h4 id="加法运算"><a href="#加法运算" class="headerlink" title="加法运算"></a>加法运算</h4><p>C(x,y) = A(x,y) + B(x,y)</p>
<ul>
<li><p>去除叠加性噪声</p>
<p>假设噪声h(x,y)均值为0，且互不相关</p>
<p>N个图像的均值定义为：</p>
<p>g(x,y) = 1/N(g0(x,y)+g1(x,y)+…+ gN(x,y))</p>
<p>期望值E(g(x,y)) = f(x,y)</p>
<p>上述图像均值将降低噪声的影响</p>
<img src="/2022/11/30/ImageProc/image-20221203165152842.png" class="" title="image-20221203165152842"></li>
<li><p>生成图像叠加效果</p>
<p>g(x,y) = αf(x,y) + βh(x,y)</p>
<p>其中α+β= 1</p>
<p>可以得到各种图像合成的效果，也可以用于</p>
<p>两张图片的衔接</p>
<img src="/2022/11/30/ImageProc/image-20221203165325281.png" class="" title="image-20221203165325281"></li>
</ul>
<h4 id="减法"><a href="#减法" class="headerlink" title="减法"></a>减法</h4><ul>
<li>显示两幅图像的差异，检测同一场景两幅图像之间的变化。如：视频中镜头边界的检测</li>
<li>去除不需要的叠加性图案，扣绿幕</li>
<li>图像分割：如分割运动的车辆，减法去掉静止部分，剩余的是运动元素和噪声</li>
</ul>
<h4 id="乘法"><a href="#乘法" class="headerlink" title="乘法"></a>乘法</h4><ul>
<li><p>图像的局部显示</p>
</li>
<li><p>用二值蒙版图像与原图像做乘法</p>
<img src="ImageProc/image-20221203165812170.png" alt="image-20221203165812170" style="zoom:50%;" /></li>
</ul>
<h4 id="非"><a href="#非" class="headerlink" title="非"></a>非</h4><ul>
<li><p>获得一个阴图像</p>
<img src="ImageProc/image-20221203170304940.png" alt="image-20221203170304940" style="zoom:50%;" /></li>
<li><p>获得一个子图像的补图像</p>
<img src="ImageProc/image-20221203170312458.png" alt="image-20221203170312458" style="zoom:50%;" /></li>
</ul>
<h4 id="与"><a href="#与" class="headerlink" title="与"></a>与</h4><ul>
<li><p>求两个子图像的相交子图</p>
<img src="/2022/11/30/ImageProc/image-20221203170356465.png" class="" title="image-20221203170356465">

<p>黑色是1，与之后白色变黑</p>
</li>
<li><p>模板运算：提取感兴趣的子图像</p>
<img src="ImageProc/image-20221203170439012.png" alt="image-20221203170439012" style="zoom:50%;" /></li>
</ul>
<h4 id="或"><a href="#或" class="headerlink" title="或"></a>或</h4><ul>
<li><p>合并子图像（应该没有这个黑边吧？）</p>
<img src="/2022/11/30/ImageProc/image-20221203170743465.png" class="" title="image-20221203170743465"></li>
<li><p>v模板运算：提取感兴趣的子图像</p>
<img src="/2022/11/30/ImageProc/image-20221203170814231.png" class="" title="image-20221203170814231"></li>
</ul>
<h4 id="异或"><a href="#异或" class="headerlink" title="异或"></a>异或</h4><ul>
<li><p>获得相交子图像,即获得相交区域。</p>
<img src="/2022/11/30/ImageProc/image-20221203170840520.png" class="" title="image-20221203170840520"></li>
</ul>
<h2 id="5-3直方图均衡化"><a href="#5-3直方图均衡化" class="headerlink" title="5.3直方图均衡化"></a>5.3直方图均衡化</h2><h4 id="均衡化"><a href="#均衡化" class="headerlink" title="均衡化"></a>均衡化</h4><p>1 为什么要进行直方图均衡化</p>
<p>我们可通过对直方图的调整，使得图像数据信息量增大，这样也就使画面更清晰。</p>
<p>2 直方图均衡化原理</p>
<p>是将原图像通过某种变换，得到一幅灰度直方图为<strong>均匀分布</strong>的新图像的方法。设图像均衡化处后，图像的直方图是平直的，即各灰度级具有相同的出现频数(大体相同)，那么由于灰度级具有均匀的概率分布，图像看起来就更清晰了</p>
<p>算法：</p>
<ol>
<li><p>确定灰度级，得到灰度级的概率分布</p>
<img src="/2022/11/30/ImageProc/image-20221203172618093.png" class="" title="image-20221203172618093"></li>
<li><p>根据概率分布得到累计的概率</p>
<img src="/2022/11/30/ImageProc/image-20221203172626177.png" class="" title="image-20221203172626177"></li>
<li><p>统一灰度级，获得一个到新图的映射关系</p>
<img src="/2022/11/30/ImageProc/image-20221203172701627.png" class="" title="image-20221203172701627">

<p>式中：L是灰度级的总数目，<em>pr</em>(<em>ri</em>)是取第i级灰度值的概率，<em>ni</em>是图像中出现第i级灰度的次数，<em>n</em>是图像中像素总数。</p>
<p>（？）统一灰度级： 这里只对图像取8个等间隔的灰度级， 变换后的值也只能选择最靠近的一个灰度级的值。因此，以1/7为量化单位进行舍入计算，得到 </p>
<p>上面的s0=0.19≈0.142857（1/7），s1=0.44≈0.428571，s2=0.65≈0.714285，s3=0.81≈0.857142，s4=0.89≈0.857142，后面都约等于1了</p>
<p>0.19*7=1.33</p>
<img src="/2022/11/30/ImageProc/image-20221203172343929.png" class="" title="image-20221203172343929">

<p>​    由上述数值可见，新图像将只有5个不同的灰度级别，可以重新定义如下一组符号</p>
<img src="ImageProc/image-20221203172401111.png" alt="image-20221203172401111" style="zoom:50%;" />

<img src="/2022/11/30/ImageProc/image-20221203172427544.png" class="" title="image-20221203172427544"></li>
</ol>
<img src="/2022/11/30/ImageProc/image-20221203173136032.png" class="" title="image-20221203173136032">

<ol>
<li>由于数字图像是离散的，因此直方图均衡化并不能产生具有理想均衡直方图的图像，但可以得到一幅灰度分布更为均匀的图像。</li>
<li>变换后一些灰度级合并，因此灰度级减少。</li>
<li>原始象含有象素数多的几个灰级间隔被拉大了，压缩的只是象素数少的几个灰度级，实际视觉能够接收的信息量大大地增强了，增加了图象的反差和图象的可视粒度。 </li>
</ol>
<p>ppt还有一个0-9范围的示例，再看一下，共10个灰度级为什么乘9啊？</p>
<p>还有一个练习题</p>
<img src="/2022/11/30/ImageProc/image-20221203173919347.png" class="" title="image-20221203173919347">

<h4 id="规定化（匹配化）"><a href="#规定化（匹配化）" class="headerlink" title="规定化（匹配化）"></a>规定化（匹配化）</h4><p>引入：在某些情况下，并不一定需要具有均匀直方图的图像，有时需要具有特定的直方图的图像，以便能够增强图像中某些灰度级。</p>
<p>直方图规定化是使原图像灰度直方图变成规定形状的直方图从而达到对图像作修正的增强方法。  </p>
<img src="/2022/11/30/ImageProc/image-20221203175501840.png" class="" title="image-20221203175501840">

<img src="/2022/11/30/ImageProc/image-20221203175523339.png" class="" title="image-20221203175523339">



<h2 id="5-4彩色增强技术"><a href="#5-4彩色增强技术" class="headerlink" title="5.4彩色增强技术"></a>5.4彩色增强技术</h2><p>1 为什么引入彩色增强技术？</p>
<p>由于人眼分辨不同彩色的能力比分别不同的灰度级的能力强，因此，把人眼无法区别的灰度变化，施以不同的彩色来提高识别率，这便是伪彩色增强的基本依据。</p>
<p>2 彩色增强技术原理</p>
<p>​    彩色增强技术是利用人眼的视觉特性，将灰度图像变成彩色图像或改变彩色图像已有彩色的分布，改善图形的可分辨性。彩色增强方法可分为伪彩色增强和假彩色增强两类。</p>
<p>3 什么是伪彩色增强技术？</p>
<p>   伪彩色技术就是将灰度图像的各个不同灰度级按照线性或非线性的映射方法变换成不同的颜色，得到一幅彩色图像的增强技术。使原图像细节更容易辨认，目标更容易识别。</p>
<p>4 伪彩色增强的方法？</p>
<p>方法有：密度分割法、灰度变换彩色法、频率域伪彩色增强</p>
<h3 id="密度分割法"><a href="#密度分割法" class="headerlink" title="密度分割法"></a>密度分割法</h3><p>基本思想：将灰度图像中的灰度级从0（黑）到M分成N个区间，Ii(i=1,2,…,N),给每个区间Ii指定一种彩色Ci，这样，便可以把一幅灰度图像变成一副伪彩色图像。</p>
<p>  特点：该方法简单直观</p>
<p>  缺点：变换出的彩色数目有限</p>
<h3 id="灰度变换彩色法"><a href="#灰度变换彩色法" class="headerlink" title="灰度变换彩色法"></a>灰度变换彩色法</h3><p>基本思想：根据色度学原理，将图像f(x,y)的灰度范围分段，经过红，绿，蓝三种不同变换TR(.),TG(.),TB(.),变成三基色分量TR(x,y),TG(x,y),TB(x,y),然后用它们分别控制彩色显示器的红、绿、蓝电子枪，便可以在彩色显示器的屏幕上合成一幅彩色图像</p>
<h3 id="频率域伪彩色增强"><a href="#频率域伪彩色增强" class="headerlink" title="频率域伪彩色增强"></a>频率域伪彩色增强</h3><p>1 把黑白图像经过傅立叶变换到频率域，在频域内用三个不同传递特性的滤波器分离成三个独立分量；</p>
<p>2 对它们进行逆傅立叶变换，得到三种代表不同频率分量的单色图像；</p>
<p>3 最后将它们作为三基色分量分别加到彩色显示器的红、绿、蓝显示通道，得到一幅彩色图像。</p>
<h3 id="伪彩色增强"><a href="#伪彩色增强" class="headerlink" title="伪彩色增强"></a>伪彩色增强</h3><p>假彩色增强是对一幅自然彩色图像或是同一景物的多光谱图像，通过映射函数变换成新的三基色分量，彩色合成使感兴趣的目标呈现与原图像不同的，奇异的颜色。其目的是将一种彩色变成另一种彩色，或把多光谱图像变成彩色图像。</p>
<h2 id="5-5图像同态滤波"><a href="#5-5图像同态滤波" class="headerlink" title="5.5图像同态滤波"></a>5.5图像同态滤波</h2><p>消除不均匀照度的影响, 增强图象细节。</p>
<p>在实际应用中，我们常常会遇到这样一类图像，它们的灰度级动态范围很大，即黑的部分很黑，白的部分很白，而我们感兴趣的图中某一部分物体灰度级范围又很小，分不清物体的灰度层次和细节。用一般的灰度线性变换是不行的，因为扩展灰度级虽可以提高物体图像的反差，但会使动态范围变大。而压缩灰度级，虽可以减少动态范围，但物体灰度层次和细节就会更看不清。只要使用合适的滤波特性函数，可以既使图像灰度动态范围压缩又能让感兴趣的物体图像灰度级扩展，从而使图像清晰，这就是所谓图像的同态增晰。进行同态增晰处理的系统称为同态系统。</p>
<p>   同态系统是服从广义叠加原理的各类非线性系统。对同态系统信号处理，特别适合处理两类信号，一类是乘法组合信号，如图像同态增晰:另一类是褶积组合信号，如语音信号处理、地震信号处理等、。</p>
<p>一般情况下，图像是物体对照明光的反射(除本身能发光的物体外)。自然景物的图像是由两个分量乘积所组成，即照明度图型和反射度图型，或称照明函数和反射函数。照明函数描述景物的照明，可以认为与景物无关:反射函数包含景物细节，也可认为与照明无关。</p>
<p>若物体受到照度明暗不匀的时候，图象上对应照度暗的部分，其细节就较难辨别。同态滤波的目的：消除不均匀照度的影响而又不损失图象细节。</p>
<p>同态滤波的理论依据：</p>
<ul>
<li><p>图象的灰度由照射分量和反射分量合成。</p>
</li>
<li><p>反射分量反映图象内容，随图象细节不同在空间上作快速变化。</p>
</li>
<li><p>照射分量在空间上通常均具有缓慢变化的性质。</p>
</li>
<li><p>反射分量的频谱落在空间高频区域，照射分量的频谱落在空间低频区域。</p>
<p> 照明函数（低频域）描述的照明度图型分量虽然变换缓慢，但变化幅度大，使图像灰度动态范围很宽，数宇化占用很多比特数，包含信息量少——压缩</p>
<p> 反射函数（高频域）描述的景物区，尤其是阴影区，灰度变化很小，层次不清，细节不明，这真是人们感兴趣的——扩展</p>
</li>
</ul>
<img src="/2022/11/30/ImageProc/image-20221203180415736.png" class="" title="image-20221203180415736">

<p>同态滤波特性曲线</p>
<img src="/2022/11/30/ImageProc/image-20221203180423694.png" class="" title="image-20221203180423694">

<h1 id="Chapter6-图像噪声的抑制"><a href="#Chapter6-图像噪声的抑制" class="headerlink" title="Chapter6.图像噪声的抑制"></a>Chapter6.图像噪声的抑制</h1><h2 id="6-1噪声"><a href="#6-1噪声" class="headerlink" title="6.1噪声"></a>6.1噪声</h2><p>1.1 什么是噪声？</p>
<p>我们说，噪声就是一些不可预测的随机信号，通常概率统计方法对其进行分析。噪声对图像处理十分重要，它影响图像处理的输入、采集、处理、输出的各个环节。</p>
<p>1.2 噪声的来源？</p>
<p>数字图像的噪声主要来源于图像的获取（数字化过程）和传输过程。</p>
<p>图像采集设备本身的问题：图像传感器受各种因素的影响，如获取中的环境条件和传感器元器件自身的质量等。</p>
<p>图像在传输过程中的问题：图像在传输过程中主要由于所用传输信道被干扰而受到噪声污染。</p>
<p>1.3 噪声的描述</p>
<p>对噪声的描述一般采用统计意义上的均值和方差。</p>
<p>数字图像信号是一个二维信号，其二维灰度分布为f(x,y)</p>
<p>图像的噪声也是二维随机过程，一般的信号噪声是一维的。</p>
<p>噪声的均值公式：噪声的均值表明了，图像中噪声的总体强度。</p>
<img src="ImageProc/image-20221204150532510.png" alt="image-20221204150532510" style="zoom: 67%;" />

<p>噪声的方差公式：噪声的方差表明了，图像中噪声分布的强弱差异。</p>
<img src="ImageProc/image-20221204150542829.png" alt="image-20221204150542829" style="zoom:67%;" />

<h3 id="噪声分类"><a href="#噪声分类" class="headerlink" title="噪声分类"></a>噪声分类</h3><h4 id="高斯噪声（正态噪声）"><a href="#高斯噪声（正态噪声）" class="headerlink" title="高斯噪声（正态噪声）"></a>高斯噪声（正态噪声）</h4><img src="/2022/11/30/ImageProc/image-20221204150656914.png" class="" title="image-20221204150656914">

<p>噪声位置是一定的，即<strong>每一点都有噪声</strong>，但噪声的幅值是随机的。</p>
<img src="ImageProc/image-20221204150721369.png" alt="image-20221204150721369" style="zoom: 67%;" />

<p>其中$z$表示灰度值，$\mu$表示灰度值$z$的平均值或期望值，$\sigma$表示$z$的标准差。$\sigma^2$是$z$的方差。$\mu=0, \sigma=1$时，称为标准正态分布。一般地，高斯噪声均值$\mu=0$</p>
<h4 id="脉冲噪声（椒盐噪声）"><a href="#脉冲噪声（椒盐噪声）" class="headerlink" title="脉冲噪声（椒盐噪声）"></a>脉冲噪声（椒盐噪声）</h4><img src="/2022/11/30/ImageProc/image-20221204151128494.png" class="" title="image-20221204151128494">

<p>噪声的幅值基本相同，但噪声出现的位置是随机的。</p>
<img src="ImageProc/image-20221204151158644.png" alt="image-20221204151158644" style="zoom:67%;" />

<p> 如果pa或pb为零，则脉冲噪声称为单极脉冲</p>
<p>如果pa或pb均不为零，则脉冲噪声称为双极脉冲噪声或椒盐噪声</p>
<p> 脉冲噪声可以为正，也可为负</p>
<p> 标定以后，脉冲噪声总是数字化为最大值（纯黑或纯白）</p>
<p> 通常，负脉冲以黑点（胡椒点）出现，正脉冲以白点（盐点）出现</p>
<h4 id="均匀分布噪声"><a href="#均匀分布噪声" class="headerlink" title="均匀分布噪声"></a>均匀分布噪声</h4><img src="ImageProc/image-20221204151806677.png" alt="image-20221204151806677" style="zoom:67%;" />

<p>z落在[a,b]的子区间内的概率只与子区间长度有关，而与子区间位置无关,因此z落在[a,b]的长度相等的子区间内的可能性是相等的，所谓的均匀指的就是这种等可能性。</p>
<h4 id="瑞利噪声"><a href="#瑞利噪声" class="headerlink" title="瑞利噪声"></a>瑞利噪声</h4><img src="/2022/11/30/ImageProc/image-20221204152057901.png" class="" title="image-20221204152057901">



<h4 id="伽马（爱尔兰）噪声"><a href="#伽马（爱尔兰）噪声" class="headerlink" title="伽马（爱尔兰）噪声"></a>伽马（爱尔兰）噪声</h4><img src="/2022/11/30/ImageProc/image-20221204152128008.png" class="" title="image-20221204152128008">

<h4 id="指数分布噪声"><a href="#指数分布噪声" class="headerlink" title="指数分布噪声"></a>指数分布噪声</h4><img src="/2022/11/30/ImageProc/image-20221204152133982.png" class="" title="image-20221204152133982">

<h3 id="噪声模型"><a href="#噪声模型" class="headerlink" title="噪声模型"></a>噪声模型</h3><p>f是图像，n是噪声</p>
<h4 id="加性噪声模型"><a href="#加性噪声模型" class="headerlink" title="加性噪声模型"></a>加性噪声模型</h4><p>加性噪声：信号和噪声相互独立。本课只考虑加性噪声。</p>
<p>G(x,y)=f(x,y)+n(x,y)</p>
<h4 id="乘性噪声模型"><a href="#乘性噪声模型" class="headerlink" title="乘性噪声模型"></a>乘性噪声模型</h4><p>乘性噪声：又称卷积噪声，乘积性噪声可以通过同态变换成为加性噪声。</p>
<p>G(x,y)=f(x,y)[1+n(x,y)]=f(x,y)+f(x,y)n(x,y)</p>
<h2 id="6-2图像退化模型"><a href="#6-2图像退化模型" class="headerlink" title="6.2图像退化模型"></a>6.2图像退化模型</h2><p>图像退化：图像在形成、记录、处理和传输过程中，由于成像系统、记录设备、传输介质和处理方法的不完善，从而导致的图像质量下降</p>
<p>图像复原就是对退化的图像进行处理，试图恢复损坏的图像，还原真面目。确定损坏过程，并尝试其逆过程进行复原。类似于图像增强，但更加客观</p>
<img src="ImageProc/image-20221204152442731.png" alt="image-20221204152442731" style="zoom:67%;" />

<p>典型表现：图像模糊、失真、有噪声</p>
<p>原因：</p>
<ul>
<li>大气的湍流效应</li>
<li>传感器特性的非线性</li>
<li>光学系统的像差</li>
<li>成像设备与被摄物体间的相对运动</li>
</ul>
<p>理论上的退化方法：图像复原可以看作图像退化的逆过程，是将图像退化的过程加以估计，建立退化的数学模型后，补偿退化过程造成的失真。</p>
<p>可行性：在图像退化确知（知道什么类型噪声）的情况下，图像退化的逆过程是有可能进行的。</p>
<p>存在问题1：但实际情况经常是退化过程并不知晓，这种复原称为<strong>盲目复原</strong>。</p>
<p>存在问题2：由于图像模糊的同时，噪声和干扰也会同时存在，这也为复原带来了困难和不确定性。</p>
<p>图像退化的一般模型</p>
<p>图像退化过程一般都看作是噪声的污染过程，而且假定噪声是加性噪声。如果系统H是一个线性、位置不变性的过程，退化图像可以表示为</p>
<img src="ImageProc/image-20221204153345711.png" alt="image-20221204153345711" style="zoom:50%;" />

<p>h(x,y)是退化函数的空间描述，其他各种影响的综合，可理解为综合所有退化因素的函数，n(x,y)是加性噪声，*表示空间卷积。图像退化/复原过程模型示意图如下：</p>
<img src="/2022/11/30/ImageProc/image-20221204153412350.png" class="" title="image-20221204153412350">

<p>f(x,y)表示一幅输入图像，g(x,y)是f(x,y)产生的一幅退化图像，H表示退化函数，η (<em>x</em>, <em>y</em>),表示外加噪声。</p>
<p>给定g(x,y)，H和η (<em>x</em>, <em>y</em>),怎样获得关于原始图像的近似估计f(x,y)？</p>
<img src="ImageProc/image-20221204153448634.png" alt="image-20221204153448634" style="zoom: 67%;" />

<p>当一幅图像中惟一存在的退化因素是噪声时,图像退化公式可变成:</p>
<img src="ImageProc/image-20221204154123517.png" alt="image-20221204154123517" style="zoom:50%;" />

<p>注意：实际的成像系统在一定条件下可以近似的看作是线性移不变系统，因此图像恢复过程中往往使用线性移不变的系统模型。该线性系统的输入是原图像（信号），响应是退化图像（信号）</p>
<p>线性移不变系统？搜了下挺复杂的</p>
<blockquote>
<p>线性系统就是一个系统的输入和输出的关系是线性关系，就是说整个系统可以分解成N多的无关独立变化，整个系统就是这些变化的累加。如 x1-&gt;y1, x2-&gt;y2; 那么A<em>x1 + B</em>x2 -&gt; A<em>y1 + B</em>y2 这就是线性系统。 叠加性，齐次性</p>
<p>线性移不变系统的形式：对于连续空间，表示一个线性系统可以用积分的形式，如Y= Sf(t,x)g(x)dt，S表示积分符号，其中f(t,x)表示的是A,B之类的线性系数。</p>
<p>上面的公式看上去和卷积很像。如果f(t,x) = F(t-x) 则就是卷积了。从f(t,x)变成F(t-x)实际上是说明F(t-x)是个线性移不变，就是说，变量的差不变化的时候，那么函数的值不变化。</p>
<p>总结：上述阐明，线性移不变系统的输出可以通过输入信号与一表征系统特性的函数g(t)的卷积得到。</p>
</blockquote>
<h2 id="6-3滤波器"><a href="#6-3滤波器" class="headerlink" title="6.3滤波器"></a>6.3滤波器</h2><h3 id="去噪"><a href="#去噪" class="headerlink" title="去噪"></a>去噪</h3><p>改善降质图像的方法有两类：</p>
<p>一类是不考虑图像降质的原因，只将图像中感兴趣的部分加以处理或突出有用的图像特征，故改善后的图像并不一定要去逼近原图像。这一类图像改善方法称为<strong>图像增强</strong>，主要目的是要提高图像的可懂度。</p>
<p>另一类方法是针对图像降质的具体原因，设法补偿降质因素，使改善后的图像尽可能地逼近原始图像。这类方法称为图像恢复或<strong>图像复原</strong>技术。</p>
<p>与图像增强的区别：图像增强不是逼近原图，而是要图像清晰；图像复原是要逼近原图。</p>
<p>卷积运算</p>
<p>首先，我们已经把图像的退化模型看作是线性移不变系统。 其次，线性移不变系统的输出可以通过输入信号与一表征系统特性的函数g(t)的卷积得到。因此，我们在处理图像退化，可以采用卷积的形式进行处理。</p>
<p>边界问题：在图像上移动模板（卷积核）至图像的边界时，在原图像中找不到与卷积核中的加权系数相对应的9个像素，即卷积核悬挂在图像缓冲区的边界上， 这种现象在图像的上下左右四个边界上均会出现。</p>
<ol>
<li>忽略图像边界数据(忽略)</li>
<li>在图像四周复制原图像边界像素的值，从而使卷积核悬挂在图像四周时可以进行正常的计算（复制）</li>
</ol>
<img src="ImageProc/image-20221204155323965.png" alt="image-20221204155323965" style="zoom:50%;" />

<h3 id="均值滤波器"><a href="#均值滤波器" class="headerlink" title="均值滤波器"></a>均值滤波器</h3><p>什么是均值滤波？</p>
<p>所谓的均值滤波是指在图像上，对待处理的像素给定一个模板，该模板包括了其周围的邻近像素。将模板中的<strong>全体像素的均值</strong>来替代原来的像素值的方法。</p>
<img src="ImageProc/image-20221204155847545.png" alt="image-20221204155847545" style="zoom:67%;" />

<p>均值滤波可以用来对<strong>椒盐（脉冲）噪声和高斯噪声</strong>进行滤波。</p>
<p>其主要优点是算法简单，计算速度快，但会造成图像一定程度上的模糊。均值滤波器（邻域平均法）的平滑效果与所采用领域的半径（模板大小）有关。半径越大，则图像的模糊程度越大。</p>
<h4 id="加权均值滤波器"><a href="#加权均值滤波器" class="headerlink" title="加权均值滤波器"></a>加权均值滤波器</h4><p>将以上的均值滤波器加以修正，可以得到加权平均滤波器，也就是邻域的不同选取方式。</p>
<img src="/2022/11/30/ImageProc/image-20221204155912968.png" class="" title="image-20221204155912968">

<p>低通：若处理的中心像素点是低点（比其他的点低），那么一平均基本没影响；若是高点（比其他的点高），则平均之后要降低。</p>
<p>高通：若中心像素点是低点(比其他点低)，则减去其他的点，更小了，不通；若是高点（比其他点高），则减去其他点，基本无影响</p>
<img src="/2022/11/30/ImageProc/image-20221204155935170.png" class="" title="image-20221204155935170">

<h3 id="中值滤波器"><a href="#中值滤波器" class="headerlink" title="中值滤波器"></a>中值滤波器</h3><p>因为噪声的出现，使该点像素比周围的像素亮（暗）许多， 给出滤波用的模板，如下图所示是一个一维的模板，对模板中的像素值由小到大排列，最终待处理像素的灰度取这个模板中排在中间位置上的像素的灰度值。</p>
<p>例如做3*3的模板，对9个数排序，取第5个数替代原来的像素值。</p>
<ul>
<li>对于椒盐噪声，中值滤波效果比均值滤波效果好。中值滤波的原理是取合理的邻近像素值来替代噪声点<ul>
<li>1 椒盐噪声是幅值近似相等但随机分布在不同位置上，图像中有干净点也有污染点。</li>
<li>2 中值滤波是选择适当的点来替代污染点的值，所以处理效果好。</li>
<li>因为噪声的均值不为0，所以均值滤波不能很好地去除噪声点。</li>
</ul>
</li>
<li>对于高斯噪声，均值滤波效果比中值滤波效果好。<ul>
<li>高斯噪声是幅值近似正态分布，但分布在每点像素上。</li>
<li>因为图像中的每点都是污染点，所中值滤波选不到合适的干净点。</li>
<li>因为正态分布的均值为0，所以根据统计数学，均值可以消除噪声。</li>
</ul>
</li>
</ul>
<h3 id="二值图像去噪"><a href="#二值图像去噪" class="headerlink" title="二值图像去噪"></a>二值图像去噪</h3><h4 id="二值图像的黑白点噪声滤波"><a href="#二值图像的黑白点噪声滤波" class="headerlink" title="二值图像的黑白点噪声滤波"></a>二值图像的黑白点噪声滤波</h4><p>方法：消去二值图像f(i，j)上的黑白的噪声，当像f(i，j)周围的8个像素的平均值为a时，若|f(i，j)-a|的值在127.5以上，则对f(i，j)的黑白进行翻转，若不到127.5则f(i，j)不变。 </p>
<img src="/2022/11/30/ImageProc/image-20221204160505324.png" class="" title="image-20221204160505324">

<h4 id="消除孤立黑像素点"><a href="#消除孤立黑像素点" class="headerlink" title="消除孤立黑像素点"></a>消除孤立黑像素点</h4><p>在4点邻域的情况下，若黑像素f(i，j)的上下左右4个像素全为白(0)，则f(i，j)也取为0。</p>
<p>在8点邻域的情况下，若黑像素f(i，j)的周围8个像素全为白(0)，则f(i，j)也取为0。</p>
<h3 id="边界保持平滑滤波器"><a href="#边界保持平滑滤波器" class="headerlink" title="边界保持平滑滤波器"></a>边界保持平滑滤波器</h3><p>前面的均值和中值滤波处理结果可知，经过平滑（特别是均值）滤波处理之后，图像就会变得模糊。我们知道，图像上的景物之所以可以辨认清楚是因为目标物之间存在边界。而对边界上的像素进行平滑滤波时，若简单的采用中值或均值，都会降低边界的灰度显著性，导致图像的模糊。</p>
<p>因此引入边界保持类的平滑滤波。</p>
<p>设置一个模板，</p>
<ul>
<li>如果模板中的像素属于同一个区域，则模板中不包含边界像素，可以进行平滑处理；</li>
<li>如果模板中的像素属于至少两个不同的区域，则模板中包含有边界像素，这时要对其进行保持，不进行平滑处理。</li>
</ul>
<p>怎样判断模板中的像素是否在同一个区域？常用方法：计算模板中所有像素的灰度方差，如果方差大，则表明模板像素属于不同区域的可能性大；反之，则模板中像素属于同一区域的可能性大。</p>
<p>灰度最小方差的均值滤波器（选择掩模滤波器）</p>
<img src="/2022/11/30/ImageProc/image-20221204162132162.png" class="" title="image-20221204162132162">

<p>选择式掩膜平滑方法取5×5的模板窗口，以中心像素为基准点，制作4个五边形、4个六边形、一个边长为3的正方形共9个形状的屏幕窗口，分别计算每个窗口内的平均值及方差。由于含有尖锐边缘的区域，方差必定比平缓区域大，因此<strong>采用方差最小的屏蔽窗口进行平均化</strong>。这种方法在完成滤波操作的同时，又不破坏区域边界的细节。这种采用9种形状的屏蔽窗口，分别计算各窗口内的灰度值方差，并采用方差最小的屏蔽窗口进行平均化的方法，也称为<strong>自适应平滑方法</strong>。</p>
<ol>
<li>以f(x,y)为中心，计算9个模板中的原有像素的灰度分布方差。</li>
<li>找出方差值最小的模板位置。</li>
<li>将所选择出的模板中像素的灰度平均值代替f(x,y).</li>
</ol>
<h3 id="K近邻平滑滤波器"><a href="#K近邻平滑滤波器" class="headerlink" title="K近邻平滑滤波器"></a>K近邻平滑滤波器</h3><p>  K近邻(KNN)平滑滤波器的核心是：在一个与待处理像素<strong>邻近的范围</strong>内，寻找出其中像素值与之最接近的K个邻点(是指灰度上最邻近)，将该<strong>K个邻点的均值（或中值）替代原像素值</strong>。</p>
<p>若待处理像素是非噪声点，则通过选择像素值与之相近的邻点，可保证在进行平滑处理时，基本上是同一区域的像素值的计算。则保证图像清晰度。</p>
<p>若待处理点是噪声点，因噪声本身的孤立性，则通过邻点的平滑处理，可对其进行抑制。</p>
<ol>
<li>以待处理像素为中心，作一个m*m的作用模板。</li>
<li>在模板中，选择K个与待处理像素的灰度差为最小的像素。</li>
<li>将这K个像素的灰度均值（中值）替换掉原来的像素值。</li>
</ol>
<p>由此，获得KNN均值滤波的结果和KNN中值滤波的结果。</p>
<h3 id="对称近邻平滑滤波器"><a href="#对称近邻平滑滤波器" class="headerlink" title="对称近邻平滑滤波器"></a>对称近邻平滑滤波器</h3><p>算法示意图如下，从模板中的“对称点对” 寻找与待处理像素相同区域的点。然后对选出的点做均值运算。所谓相同区域，是相对的概念，可以是较为接近的，课本有此算法，下面这个图C1的选取就并不是严格的相同</p>
<img src="/2022/11/30/ImageProc/image-20221204163226417.png" class="" title="image-20221204163226417">

<h3 id="Sigma平滑滤波器"><a href="#Sigma平滑滤波器" class="headerlink" title="Sigma平滑滤波器"></a>Sigma平滑滤波器</h3><p>根据统计数学的原理，属于同一类别的元素的置信区间，落在均值附近±2σ 范围之内。</p>
<p>Sigma滤波器是构造一个模板，计算模板的标准差σ，置信区间为当前像素值的±2σ范围。</p>
<p>将模板中落在置信范围内的像素的均值替换原来的像素值。</p>
<img src="/2022/11/30/ImageProc/image-20221204163806502.png" class="" title="image-20221204163806502">

<h3 id="高斯平滑滤波器"><a href="#高斯平滑滤波器" class="headerlink" title="高斯平滑滤波器"></a>高斯平滑滤波器</h3><p>所以这个为什么第七章才讲啊？</p>
<p>高斯滤波器是一类根据高斯函数的形状来选择权值的线性平滑滤波器。高斯平滑滤波器对于抑制服从正态分布的噪声非常有效。(移除细节)</p>
<p>其中，高斯分布参数<strong>Sigma</strong>决定了高斯函数的宽度。对于图像处理来说，常用二维零均值离散高斯函数作平滑滤波器。</p>
<p>思路：高斯滤波就是对整幅图像进行加权平均的过程，每一个像素点的值，都由其本身和邻域内的其他像素值经过加权平均后得到。</p>
<p>两种高斯模板：</p>
<img src="/2022/11/30/ImageProc/image-20221204180159535.png" class="" title="image-20221204180159535">

<p>理论上来讲，图像中每点的分布都不为零，这也就是说每个像素的计算都需要包含整幅图像。在实际应用中，在计算高斯函数的离散近似时，在大概3σ距离之外的像素都可以看作不起作用，（σ=1时，在3σ内的概率为99.73%）那些像素的计算也就可以忽略。</p>
<p>它在对邻域内像素灰度进行平均时，给予了不同位置像素不同的权值。上图显示的是3×3邻域的高斯模板，模板上越是靠近邻域中心的位置，其权值就越高。如此安排权值的意义在于用此模板进行图像平滑时，在对图像细节进行模糊的同时，可以更多地保留图像总体的灰度分布特征。</p>
<h2 id="6-4产生噪声"><a href="#6-4产生噪声" class="headerlink" title="6.4产生噪声"></a>6.4产生噪声</h2><h3 id="高斯噪声"><a href="#高斯噪声" class="headerlink" title="高斯噪声"></a>高斯噪声</h3><p>(1)取得图像大小、数据区，并把数据区复制到缓冲区中；</p>
<p>(2)循环取得各点像素值；</p>
<p>(3)取得随机数（rand()/1024）；</p>
<p>(4)该点像素值加上随机数；</p>
<p>(5)把缓冲区中改动的数据复制到原数据区中。</p>
<h3 id="椒盐噪声"><a href="#椒盐噪声" class="headerlink" title="椒盐噪声"></a>椒盐噪声</h3><p>(1)取得图像大小、数据区，并把数据区复制到缓冲区中；</p>
<p>(2)循环取得各点像素值；</p>
<p>(3)若产生的随机数大于特定值，把该点置0；（只有这些特定点，才有噪声，值为0）</p>
<p>(4)把缓冲区中改动的数据复制到原数据区中。</p>
<h1 id="Chapter7-图像锐化与边缘检测"><a href="#Chapter7-图像锐化与边缘检测" class="headerlink" title="Chapter7.图像锐化与边缘检测"></a>Chapter7.图像锐化与边缘检测</h1><h2 id="7-1引言"><a href="#7-1引言" class="headerlink" title="7.1引言"></a>7.1引言</h2><p>问题的提出：一般说，图像的能量主要集中在其低频部分，噪声所在的频段主要在高频段（随机噪声叠加之后数值变大了？），同时图像边缘信息也主要集中在其高频部分（边缘比较黑吧）。这将导致原始图像在平滑处理之后，图像边缘和图像轮廓模糊的情况出现。</p>
<p>解决：为了减少这类不利效果的影响，就需要利用图像锐化技术，使图像的边缘变得清晰。</p>
<p>图像锐化处理目的:增强图像边缘，使目标物体的边缘鲜明，以便于提取目标物体的边界、对图像进行分割、目标区域识别、区域形状提取等，为图像理解和分析打下基础。其实就是为了加强图像中景物的边缘和轮廓。锐化的作用是要使灰度边缘的反差增强。</p>
<p>图像锐化的基本方法：因为边缘和轮廓都位于灰度<strong>突变</strong>的地方。所以锐化算法的实现是基于微分作用</p>
<p>图像锐化的应用：目前它已成为机器视觉研究领域最活跃的课题之一，在工程应用中占有十分重要的地位。</p>
<p>两种方法：</p>
<ul>
<li>高通滤波：图像的边缘或线条的细节（边缘）部分 与图像频谱的高频分量相对应，因此采用高通滤波让高频分量顺利通过，并适当抑制中低频分量，是图像的细节变得清楚，实现图像的锐化。</li>
<li>空域微分法：空域的方法——微分法。邻域平均法或加权平均法可以平滑图像，反过来利用对应的微分算法可以锐化图像。由于图像模糊的实质是图像受到平均或积分运算造成的，所以为了把图像中任何方向伸展的边缘模糊的轮廓变得清晰，可以对图像进行逆运算如微分运算，从而使图像清晰化。</li>
</ul>
<h3 id="灰度变换曲线"><a href="#灰度变换曲线" class="headerlink" title="灰度变换曲线"></a>灰度变换曲线</h3><p>画面逐渐由亮变暗时，其灰度值的变换是斜坡变化；</p>
<p>当出现孤立点，一般是噪声点，其灰度值的变化是一个突起的尖峰；</p>
<p>若进入平缓变化的区域，则其灰度变化为一个平坦段；</p>
<p>如果图像出现一条细线，则其灰度变化是一个比孤立点略显平缓的尖峰。</p>
<p>当图像由黑突变到亮，则其灰度变化是一个阶跃。</p>
<p>通过分析，图像中的细节是指画面的灰度变化情况，可采用微分算子来描述数据变化。</p>
<p>如图，逐渐亮变暗-孤立点-细线-突变-平缓</p>
<img src="/2022/11/30/ImageProc/image-20221204164540904.png" class="" title="image-20221204164540904">

<p>原图-一阶导-二阶导</p>
<img src="ImageProc/image-20221204164655112.png" alt="image-20221204164655112" style="zoom:50%;" />

<p>图像沿着<strong>中心</strong>并包含噪声点的此图像的水平剖面图。这张剖面图是将要用以说明该图的一维函数。图C是简化的剖面图，该图中取了足够多的点，以便于分析噪声点、线、物体边缘的一阶和二阶微分结果。</p>
<p>从左到右横穿剖面图，讨论一阶和二阶微分性质。</p>
<ul>
<li>图像过渡的边缘（也就是沿整个斜坡），一阶微分都不为零，经过二阶微分后，非零值只出现在斜坡的起始处和终点处。得出结论：一阶微分产生较粗的边缘，二阶微分则细。</li>
<li>孤立的噪声点。在孤立点及其周围点，二阶微分比一阶微分响应要强。</li>
<li>细线。也是一种细节。双线</li>
</ul>
<p>一阶微分和二阶微分的区别:</p>
<p>(1)一阶微分处理通常会产生较宽的边缘，二阶微分处理得到的边缘则<strong>细</strong>。</p>
<p>(2)二阶微分处理对<strong>细节</strong>有较强的响应,如细线和孤立点</p>
<p>(3)一阶微分处理一般对灰度阶梯有较强的响应</p>
<p>(4)二阶微分处理对灰度级阶梯变化产生<strong>双响应</strong></p>
<p>(5)二阶微分在图像中灰度值变化相似时,对线的响应要比对阶梯强,且点比线强.</p>
<p>小结：大多数应用中,对图像增强来说.二阶微分处理比一阶微分好,因为形成细节的能力强. 而一阶微分处理主要用于提取边缘。</p>
<h2 id="7-2微分运算"><a href="#7-2微分运算" class="headerlink" title="7.2微分运算"></a>7.2微分运算</h2><p>寄，看ppt吧</p>
<h3 id="纵向微分运算-amp-横向微分运算"><a href="#纵向微分运算-amp-横向微分运算" class="headerlink" title="纵向微分运算&amp;横向微分运算"></a>纵向微分运算&amp;横向微分运算</h3><p>横向x和纵向y的微分公式，就是后面减前面</p>
<img src="/2022/11/30/ImageProc/image-20221204170137653.png" class="" title="image-20221204170137653">

<p>常用模板，Roberts算子</p>
<p>计算结果出现了小于0的像素值解决：</p>
<ol>
<li><p>整体加一个正整数，以保证所有的像素值均为正。这样做的结果是：可以获得类似浮雕的效果。</p>
<img src="ImageProc/image-20221204170436353.png" alt="image-20221204170436353" style="zoom:50%;" /></li>
<li><p>将所有的像素值取绝对值。这样做的结果是，可以获得对边缘的有方向提取</p>
</li>
</ol>
<h3 id="双向一次微分运算"><a href="#双向一次微分运算" class="headerlink" title="双向一次微分运算"></a>双向一次微分运算</h3><p>对灰度图像f在纵方向和横方向两个方向进行微分。该算法是同时增强水平和垂直方向的边缘。该算法的数学表达式为：G(i,j)=sqrt{[f(i,j)-f(i,j-1)]^2+[f(i,j)-f(i-1,j)]^2}就是<strong>梯度运算</strong></p>
<img src="/2022/11/30/ImageProc/image-20221204171108502.png" class="" title="image-20221204171108502">

<h2 id="7-3梯度锐化"><a href="#7-3梯度锐化" class="headerlink" title="7.3梯度锐化"></a>7.3梯度锐化</h2><p>梯度锐化的一般思路：由梯度的计算可知，在图像灰度变化较大的边沿区域其梯度值大，在灰度变化平缓的区域梯度值较小，而在灰度均匀的区域其梯度值为零。</p>
<p>可根据得到的梯度值来返回像素的值，如将梯度值大的像素设置成白色，梯度值小的设置为黑色，这样就可以将边缘提取出来了，或者是加强梯度值大的像素灰度值就可以突出细节了达到了锐化的目的。</p>
<p>G(i,j)=sqrt{[f(i,j)-f(i,j-1)]^2+[f(i,j)-f(i-1,j)]^2}</p>
<p>梯度锐化常用的方法有：</p>
<ol>
<li><p>直接以梯度值代替：计算出的梯度值直接等于该点灰度值</p>
</li>
<li><p>辅以门限判断</p>
<p>比较像素的梯度是否大于T，是则将梯度值加100，不是则将该像素点的灰度值恢复（就是不变），如果梯度大于255，将其置为255；</p>
<img src="ImageProc/image-20221204171512160.png" alt="image-20221204171512160" style="zoom: 67%;" /></li>
<li><p>给边缘规定一个特定的灰度级</p>
<p>比较像素的梯度是否大于T，是则将灰度值置为La，否则灰度值不变。</p>
<img src="ImageProc/image-20221204171647016.png" alt="image-20221204171647016" style="zoom: 80%;" /></li>
<li><p>给背景规定灰度级：类似3，为背景指定La</p>
<img src="ImageProc/image-20221204171726468.png" alt="image-20221204171726468" style="zoom:67%;" /></li>
<li><p>根据梯度二值化图像</p>
<img src="/2022/11/30/ImageProc/image-20221204171800047.png" class="" title="image-20221204171800047"></li>
</ol>
<h2 id="7-4边缘检测"><a href="#7-4边缘检测" class="headerlink" title="7.4边缘检测"></a>7.4边缘检测</h2><p>锐化是把图像的低频边缘高频化，使得图像看起来更加有轮廓</p>
<p>边缘检测就是检测到图像中的边缘，可以作为锐化的基础，也可以用于分割</p>
<p>一阶微分算法：</p>
<h3 id="Roberts算子"><a href="#Roberts算子" class="headerlink" title="Roberts算子"></a>Roberts算子</h3><p>又称交叉微分算法</p>
<p>特点：对具有陡峭的低噪声的图像处理效果较好，但提取的边缘较粗，边缘定位不是很准确。</p>
<img src="/2022/11/30/ImageProc/image-20221204173042929.png" class="" title="image-20221204173042929"><img src="/2022/11/30/ImageProc/image-20221204173047417.png" class="" title="image-20221204173047417">

<img src="/2022/11/30/ImageProc/image-20221204173101536.png" class="" title="image-20221204173101536">

<p>只找到了绝对值的公式图，平方和再开方要更好些。</p>
<p>每个像素依次循环，用Roberts边缘检测算子分别计算图像中各点灰度值，对它们平方之和，再开方。</p>
<p>效果图：</p>
<img src="/2022/11/30/ImageProc/image-20221204173243696.png" class="" title="image-20221204173243696">

<h3 id="Sobel算子"><a href="#Sobel算子" class="headerlink" title="Sobel算子"></a>Sobel算子</h3><img src="/2022/11/30/ImageProc/image-20221204173258007.png" class="" title="image-20221204173258007"><img src="/2022/11/30/ImageProc/image-20221204173300127.png" class="" title="image-20221204173300127">

<p>特点：锐化的边缘信息定位比较准确；对灰度渐变和噪声较多的图像处理效果比较好。</p>
<ol>
<li>分别设置Sobel算子的两个模板，分别对两个缓冲区中的图像进行卷积计算。</li>
<li>两个缓存图像每个像素依次循环，取两个缓存中各个像素灰度值较大者。</li>
</ol>
<img src="/2022/11/30/ImageProc/image-20221204174034007.png" class="" title="image-20221204174034007">



<h3 id="Prewitt算子"><a href="#Prewitt算子" class="headerlink" title="Prewitt算子"></a>Prewitt算子</h3><img src="/2022/11/30/ImageProc/image-20221204174046587.png" class="" title="image-20221204174046587">

<p>特点：与Sobel相比，有一定的抗干扰性。图像效果比较干净。</p>
<img src="/2022/11/30/ImageProc/image-20221204174102750.png" class="" title="image-20221204174102750">

<h3 id="Krisch边缘检测"><a href="#Krisch边缘检测" class="headerlink" title="Krisch边缘检测"></a>Krisch边缘检测</h3><p>以下8个卷积核组成了Kirsch边缘检测算子。图像中的每个点都用8个模板进行卷积，</p>
<p>所有8个方向中的最大值作为边缘幅度图像输出</p>
<img src="ImageProc/image-20221204174235694.png" alt="image-20221204174235694" style="zoom:50%;" />

<p>分别设置Kirsch算子的模板1和模板2，调用Templat()模板函数分别对两个缓冲区中的图像进行卷积计算。求出两幅缓存图像中每个像素的较大灰度值存放在缓存图像1中，并将缓存图像1拷贝到缓存图像2中。</p>
<p>以此类推，分别设置Kirsch算子的模板3、模板4、模板5、模板6、模板7和模板8，每次计算后，求出两幅缓存图像中灰度值较大者存放在缓存图像1中。</p>
<p>最后将得到的结果缓存图像1复制到原图。</p>
<img src="/2022/11/30/ImageProc/image-20221204174309087.png" class="" title="image-20221204174309087">





<p>二阶微分算法：</p>
<h3 id="LoG-Laplacian高斯-拉普拉斯算子"><a href="#LoG-Laplacian高斯-拉普拉斯算子" class="headerlink" title="LoG_Laplacian高斯-拉普拉斯算子"></a>LoG_Laplacian高斯-拉普拉斯算子</h3><p>特点：Laplacian算子获得的边界是比较细致的边界。反映的边界信息包括了许多的细节信息，但是所反映的边界不是太清晰。Laplace算子对噪声敏感</p>
<img src="ImageProc/image-20221204175503469.png" alt="image-20221204175503469" style="zoom: 67%;" />

<p>laplacian变形算子</p>
<img src="/2022/11/30/ImageProc/image-20221204175726708.png" class="" title="image-20221204175726708">

<p>还有一个5*5的</p>
<img src="ImageProc/image-20221204180914835.png" alt="image-20221204180914835" style="zoom:67%;" />

<img src="/2022/11/30/ImageProc/image-20221204180930231.png" class="" title="image-20221204180930231">

<h3 id="Wallis算子"><a href="#Wallis算子" class="headerlink" title="Wallis算子"></a>Wallis算子</h3><img src="/2022/11/30/ImageProc/image-20221204175801003.png" class="" title="image-20221204175801003">

<p>在前面的算法公式中注意以下几点：</p>
<p>1）为了防止对0取对数，计算时实际上是用  log(f(i,j)+1);</p>
<p>2）因为对数值很小log(256)=5.45,所以计算时用46*log(f(i,j)+1)（46=255/log(256)）</p>
<p>  Wallis算法考虑了人眼视觉特性，因此，与Laplacian等其他算法相比，可以对<em>暗区的细节</em>进行比较好的锐化。</p>
<h3 id="Canny算子"><a href="#Canny算子" class="headerlink" title="Canny算子"></a>Canny算子</h3><p>Canny给出了评价边缘检测性能优劣的三个指标：</p>
<ol>
<li>好的信噪比，即将非边缘点判定为边缘点的概率要低，将边缘点判为非边缘点的概率要低；</li>
<li>高的定位性能，即检测出的边缘点要尽可能在实际边缘的中心；</li>
<li>对单一边缘仅有唯一响应，即单个边缘产生多个响应的概率要低，并且虚假响应边缘应该得到最大抑制。</li>
</ol>
<p>用一句话说，就是希望在提高对景物边缘的敏感性的同时，可以抑制噪声的方法才是好的边缘提取方法。</p>
<p>Canny算子求边缘点具体算法步骤如下：</p>
<ol>
<li><p>用高斯滤波器平滑图像．</p>
<img src="/2022/11/30/ImageProc/image-20221204180159535.png" class="" title="image-20221204180159535"></li>
<li><p>用一阶偏导有限差分计算梯度幅值和方向.</p>
<img src="/2022/11/30/ImageProc/image-20221204180638619.png" class="" title="image-20221204180638619"></li>
<li><p>对梯度幅值进行非极大值抑制．</p>
<p>仅仅得到全局的梯度并不足以确定边缘，因此为确定边缘，必须保留局部梯度最大的点，而抑制非极大值。</p>
<p>解决方法：利用梯度的方向，将梯度离散为圆周的四个扇区，以便用3×3的模板做运算。四个扇区的标号为0到3，对应3*3邻域的四种可能组合。在每一点上，邻域的中心象素M与沿着梯度线的两个象素相比。如果M的梯度值不比沿梯度线的两个相邻象素梯度值大，则令M=0。</p>
<img src="/2022/11/30/ImageProc/image-20221204180745788.png" class="" title="image-20221204180745788">

<p>扇区1-5,2-6,3-7…以此类推</p>
</li>
<li><p>用双阈值算法检测和连接边缘</p>
<p>对非极大值抑制图像作用两个阈值th1和th2，两者关系th1=0.4th2。我们把梯度值小于th1的像素的灰度值设为0，得到图像1。然后把梯度值小于th2的像素的灰度值设为0，得到图像2。由于图像2的阈值较高，去除大部分噪音，但同时也损失了有用的边缘信息。而图像1的阈值较低，保留了较多的信息，我们可以以图像2为基础，以图像1为补充来连结图像的边缘。</p>
<p>链接边缘的具体步骤如下：</p>
<p>对图像2进行扫描，当遇到一个非零灰度的像素p(x,y)时，跟踪以p(x,y)为开始点的轮廓线，直到轮廓线的终点q(x,y)。</p>
<p>考察图像1中与图像2中q(x,y)点位置对应的点s(x,y)的8邻近区域。如果在s(x,y)点的8邻近区域中有非零像素s(x,y)存在，则将其包括到图像2中，作为r(x,y)点。从r(x,y)开始，重复第一步，直到我们在图像1和图像2中都无法继续为止。</p>
<p>当完成对包含p(x,y)的轮廓线的连结之后，将这条轮廓线标记为已经访问。回到第一步，寻找下一条轮廓线。重复第一步、第二步、第三步，直到图像2中找不到新轮廓线为止。</p>
<p>至此，完成canny算子的边缘检测。实际就是默认图像2中噪声点全被去掉了，只有边界点。</p>
</li>
</ol>
<h3 id="LOG算子"><a href="#LOG算子" class="headerlink" title="LOG算子"></a>LOG算子</h3><img src="/2022/11/30/ImageProc/image-20221204180847728.png" class="" title="image-20221204180847728">

<h1 id="Chapter8-图像分割与测量"><a href="#Chapter8-图像分割与测量" class="headerlink" title="Chapter8.图像分割与测量"></a>Chapter8.图像分割与测量</h1><p>什么是图像分割</p>
<ul>
<li>在图像分析中，通常要将所关心的目标从图像中提取出来，这种从图像中将某个特定区域与其他部分进行分离并提取出来的处理，就是图像分割。就是指<strong>将一幅图像分解为若干互不交叠的、有意义的、具有相同性质的区域。</strong>  </li>
<li>图像分割将图像分为一些有意义的子区域，然后可以对这些区域进行描述，相当于提取出某些目标区域图像的特征，判断图像中是否有感兴趣的目标。</li>
</ul>
<p>为什么要进行图像分割</p>
<ul>
<li>图像分割与测量是图像识别和图像理解的基本前提步骤。图像分割质量的好坏直接影响后续图像处理的效果。</li>
<li>分割的目的就是将图像划分为不同的区域。实际图像分割通过某种方法，使得画面场景被分为“目标物”及“非目标物”两类，即将图像的像素变换为黑、白两种。因为结果图像为二值图像，所以通常又称图像分割为图像的二值化处理。</li>
</ul>
<p>图像分割特征</p>
<ul>
<li>分割出来的各区域对某种性质例如灰度，纹理而言具有相似性，区域内部是连通的且没有过多小孔；</li>
<li>区域边界是明确的；</li>
<li>相邻区域对分割所依据的性质有明显的差异。</li>
</ul>
<p>图像分割基础</p>
<ul>
<li>基于亮度值的两个基本特性之一: （跳跃性）不连续性和相似性.</li>
<li>第1类性质的应用途径是基于亮度的跳跃（不连续）变化分割图像,比如图像的边缘. </li>
<li>第2类的主要应用途径是依据事先制定的准则将图像分割为相似的区域.门限(阈值)处理、区域生长、区域分离和聚合都是这类方法的实例。</li>
</ul>
<img src="/2022/11/30/ImageProc/image-20221204201224187.png" class="" title="image-20221204201224187">

<p>图像分割方法</p>
<ul>
<li>基于图像灰度分布的阈值方法</li>
<li>基于图像灰度空间分布的阈值方法</li>
<li>边缘检测法</li>
<li>区域提取方法</li>
</ul>
<h2 id="8-1阈值分割法"><a href="#8-1阈值分割法" class="headerlink" title="8.1阈值分割法"></a>8.1阈值分割法</h2><h3 id="基于图像灰度分布的阈值分割"><a href="#基于图像灰度分布的阈值分割" class="headerlink" title="基于图像灰度分布的阈值分割"></a>基于图像灰度分布的阈值分割</h3><p>设图像阈值的分割就是确定某个阈值Th，根据图像中每个像素的灰度值大于或小于该阈值Th来进行图像分割。</p>
<p>利用图像中要提取的目标物体和背景在灰度上的差异，选择一个合适的阈值。</p>
<img src="ImageProc/image-20221204201639850.png" alt="image-20221204201639850" style="zoom:67%;" />

<p>阈值选择</p>
<ul>
<li>全局阈值：是对整幅图像使用同一个阈值做处理分割。适用背景和前景有明显对比的图像。多数情况下，物体和背景的对比度在图像中不是各处一样的，这样很难用一个统一的阈值将物体与图像分开。针对这类图像，可以根据局部特性分别采用不用的阈值进行分割。</li>
<li>自适应阈值：实际处理时，需要按具体问题将图像分成若干子区域分别选取阈值，或动态地根据一定的邻域范围选择每点处阈值，进行图像分割。</li>
</ul>
<h3 id="阈值选择方法"><a href="#阈值选择方法" class="headerlink" title="阈值选择方法"></a>阈值选择方法</h3><h4 id="直方图门限选择"><a href="#直方图门限选择" class="headerlink" title="直方图门限选择"></a>直方图门限选择</h4><p>阈值T可通过分析边缘检测输出的直方图来确定。假设，一幅图像只有物体和背景两部分组成，其灰度级直方图成明显的双峰值，如图。 </p>
<img src="/2022/11/30/ImageProc/image-20221204202132664.png" class="" title="image-20221204202132664">

<p>​    在此情况下，选取双峰间的谷底处的灰度值T作为阈值，即可将物体和背景很好地分割开。阈值分割法可用数学表达式来描述。设图像为f(i，j)，其灰度级范围为[z1，z2]，<strong>设T为阈值</strong>，是z1和z2内任一值，可得一幅二值图像，其数学表达式为:</p>
<img src="ImageProc/image-20221204202220513.png" alt="image-20221204202220513" style="zoom:50%;" />

<p>以此类推，三峰甚至多峰情况也可以选取多个T值作为阈值变为二值化（只要临近的两个区域颜色不一样能分开就行）图像。</p>
<p>但是对于细节变化特别多的图像，对于阈值没那么明显的图像（没有明显双峰特性）该方法效果比较差。比如lena图</p>
<img src="/2022/11/30/ImageProc/image-20221204203257467.png" class="" title="image-20221204203257467">



<h4 id="半阈值选择图像分割"><a href="#半阈值选择图像分割" class="headerlink" title="半阈值选择图像分割"></a>半阈值选择图像分割</h4><p>阈值方法，不论图像的直方图具有双峰还是多峰值，经过阈值化后均将原始灰度级多值图像变成二值图像，假如希望阈值后的图像<strong>只把图像的背景表示成二值图像</strong>（即背景不是最白（用1表示）就是最黑（用0表示））<strong>而图像中的物体仍为多值图像</strong>。此时，可采用半阈值技术，把物体从背景中分离出来。</p>
<p>像素灰度值与阈值之差小于T，将像素置为0，否则保持灰度值不变</p>
<img src="/2022/11/30/ImageProc/image-20221204203450689.png" class="" title="image-20221204203450689">

<h4 id="迭代阈值图像分割"><a href="#迭代阈值图像分割" class="headerlink" title="迭代阈值图像分割"></a>迭代阈值图像分割</h4><p>迭代的方法产生阈值，可以通过程序自动计算出比较合适的分割阈值。其计算方法是这样的：</p>
<p>（1）选择阈值T，通常可以选择图像的平均灰度值来作为初始阈值；</p>
<p>（2）通过初始阈值T，把图像的平均灰度值分成两组R1和R2；</p>
<p>（3）计算着两组平均灰度值μ1和μ2；</p>
<p>（4）重新选择阈值T，新的T定义为：T’=(μ1+μ2)/2;</p>
<p>循环做第二步到第四步，一直到两组的平均灰度值μ1和μ2不在发生改变，那么我们就获得了所需要的阈值</p>
<h4 id="最大类间方差"><a href="#最大类间方差" class="headerlink" title="最大类间方差"></a>最大类间方差</h4><p>ppt</p>
<h4 id="最小类内方差"><a href="#最小类内方差" class="headerlink" title="最小类内方差"></a>最小类内方差</h4><p>ppt</p>
<p>方差是表征数据分布不均衡性的统计量。因此要通过阈值将图像分割成两类，显然，适当的阈值使得两类数据间的方差越大越好，表明同一类中具有一定的相似性。</p>
<p>因此用类间与类内方差的比作为选择阈值的评价参数</p>
<p>最大类间、类内方差比法：就是类间方差与类内方差的比最大。</p>
<p>这个算法看看ppt吧</p>
<h4 id="最大熵方法"><a href="#最大熵方法" class="headerlink" title="最大熵方法"></a>最大熵方法</h4><p>ptt(雾)</p>
<p>熵：是信息论中对不确定性的度量，是对数据中所包含信息量大小的度量。</p>
<p>熵越大，则表明获得的信息量就越大，也就是不确定性越大。</p>
<p>最大熵方法的基本思想：选择适当的阈值将图像分成两类，两类的平均熵之和为最大时，可从图像中获得最大信息量，以此来确定最佳阈值。</p>
<ol>
<li>求图像中所有像素灰度的分布概率</li>
<li>用初始阈值将图像分为C1和C2两类</li>
<li>分别计算两类的平均相对熵E1,E2</li>
<li>选择最佳阈值，使E1+E2能够取最大值。</li>
</ol>
<h4 id="P-参数法"><a href="#P-参数法" class="headerlink" title="P-参数法"></a>P-参数法</h4><p>基本思想：对固定分辨率下的目标物，根据目标物在画面中所占的比例来选择阈值，进行二值化处理。</p>
<p>适用： 适用于有标准图像的情况，也就是事先知道目标物在图像中所占比例。</p>
<p>原理</p>
<ul>
<li>如下图所示，假设目标物为暗，背景为亮；</li>
<li>先试探性地给出一个阈值（黄色） ，统计目标物的像素点数在整幅图中所占的比例是否满足要求（？），是，则阈值合适；</li>
<li>否则，阈值则偏大（右）或者偏小（左），再进行调整，直到满足要求（白色）。</li>
</ul>
<img src="ImageProc/image-20221204205220361.png" alt="image-20221204205220361" style="zoom:67%;" />

<p>步骤</p>
<p>1）设图像的大小为m*n，计算得到原图的灰度直方图h；</p>
<p>2）得到理想状态下目标物所占画面的比例p；怎么得到？</p>
<p>3）尝试性地给定一个阈值Th=Th0；</p>
<p>4）计算在Th下判定的目标物的像素点数N; </p>
<p>5）判断ps=N/(m*n)是否接近p？</p>
<p>   是，  则输出结果；</p>
<p>   否则，Th=Th+dT; </p>
<p>​        (if ps&lt;p, 则dT&gt;0;else dT&lt;0)， </p>
<p>​        转4），直到满足条件。</p>
<p>p-参数法对于<strong>已知目标物在画面中所占比例</strong>的情况下使用比较有效。</p>
<h3 id="基于图像灰度空间分布的阈值方法"><a href="#基于图像灰度空间分布的阈值方法" class="headerlink" title="基于图像灰度空间分布的阈值方法"></a>基于图像灰度空间分布的阈值方法</h3><p>局部阈值法？前面写的标题名字，后面说的是局部</p>
<p>前面的阈值方法是单一阈值。即对整幅图像采用一个被确定的阈值进行分割处理。也可以进行局部阈值算法。只对简单图像（即目标与背景比较容易区分）有效，但对于一个较为复杂的图像 ，就会有一些问题。</p>
<p>如图显示全局阈值效果不如局部阈值分割效果。这是因为光照不均造成的（光源位于画面左侧）。</p>
<p>用全局阈值，会导致远离光源的右侧气泡区域，提取得到的面积远远小于实际面积，这样就会影响后继的定量分析结果。</p>
<p>局部阈值：将图像进行一定的等分，在每个子块上，光照不均的影响就可忽略不计。在每个子块上采用前面给出的阈值方法，最终可达到理想的效果。</p>
<img src="/2022/11/30/ImageProc/image-20221204205632081.png" class="" title="image-20221204205632081">

<h4 id="灰度-局部灰度均值散布图法"><a href="#灰度-局部灰度均值散布图法" class="headerlink" title="灰度-局部灰度均值散布图法"></a>灰度-局部灰度均值散布图法</h4><p>原理：如果某个像素与其周围领域中的均值偏差较大，则说明该点是边界上的点或者是噪声点。</p>
<p>构造灰度－局部灰度均值散布图</p>
<p>以图像灰度为横轴，<strong>局部灰度均值（如3*3模板下的均值）为纵轴</strong>，构造一个图像分布的散布图，</p>
<p>对于对角线上的点分布，对应于目标或者背景内部的点，对于离开对角线的点，则对应于区域边界上的点。</p>
<img src="ImageProc/image-20221204210826656.png" alt="image-20221204210826656" style="zoom:67%;" />

<h4 id="二维最大熵法"><a href="#二维最大熵法" class="headerlink" title="二维最大熵法"></a>二维最大熵法</h4><p>二维最大熵法基于图像的二维直方图。</p>
<p>图像的二维直方图定义如下：</p>
<img src="ImageProc/image-20221204211227307.png" alt="image-20221204211227307" style="zoom:67%;" />

<p>其中 M，N是表示图像大小，Ni,j表示图像灰度值是i, 邻域平均灰度值为j的像素的个数。</p>
<img src="/2022/11/30/ImageProc/image-20221204211256339.png" class="" title="image-20221204211256339">

<p>其中区域1和2表示背景和目标像素，区域3和4通常表示边界和噪声信息。阈值向量(t,s)，t表示灰度值，s表示像素邻域均值（通常是8邻域）</p>
<h3 id="边缘检测法"><a href="#边缘检测法" class="headerlink" title="边缘检测法"></a>边缘检测法</h3><h4 id="梯度直方图法"><a href="#梯度直方图法" class="headerlink" title="梯度直方图法"></a>梯度直方图法</h4><p>关于边缘检测类的阈值方法，在前一章中介绍了Canny算子和LOG算子的边缘检测。这些方法都是通过对边缘变化率的分析得到的。</p>
<p>这里是基于的边缘检测类的阈值方法，也就是用边缘检测方法来得到二值化阈值</p>
<img src="/2022/11/30/ImageProc/image-20221204211555163.png" class="" title="image-20221204211555163">

<p>下图是对前图进行Sobel锐化结果的梯度值统计直方图。由于图像中像素间的相关性较强，因此低梯度（接近0处）的像素个数是大多数，从而该直方图无法获得直接选择阈值的提示信息。对该直方图进行修正，获得一个<strong>加权梯度直方图</strong>（？）</p>
<img src="/2022/11/30/ImageProc/image-20221204211802308.png" class="" title="image-20221204211802308">

<p>加权梯度直方图的设计方法是，通过对梯度分布进行加权修正，增大直方图的分布细节。一般采用的方法是，对高梯度区加较大的权值，以减小均匀区域内像素点对直方图的贡献，增加边界上的点对直方图的贡献。如前图 (b)所示，通过这样的处理之后，选择第一个峰值为最佳阈值点即可。</p>
<p>前图 (c)所示，是采用该方法对一幅国际标准测试图像进行处理的结果，经过计算得到该图例的分割阈值为Th* =190。</p>
<h2 id="8-2轮廓提取"><a href="#8-2轮廓提取" class="headerlink" title="8.2轮廓提取"></a>8.2轮廓提取</h2><h3 id="轮廓提取法"><a href="#轮廓提取法" class="headerlink" title="轮廓提取法"></a>轮廓提取法</h3><p>图像边缘是图像局部特性不连续性（灰度突变、颜色突变等）的反映，它标志着一个区域的终结和另一个区域的开始。</p>
<p>二值图像的轮廓提取的基本原理：就是掏空内部点，如果原图中有一点为黑，且它的8个相邻点皆为黑，则将该点删除（意思就是把该点置为背景白色，而轮廓即边始终是黑色）。</p>
<p>注意：</p>
<ul>
<li>对于非二值图像，要先进行二值化处理。</li>
<li>轮廓提取其实是取一个物体的边。</li>
</ul>
<p>算法</p>
<ul>
<li>将像素点的8邻域像素读入数组中</li>
<li>如果每一个邻域像素的灰度值和中心点的灰度值相差小于10，则认为邻域像素和中心点相同。</li>
<li>如果8个邻域像素都和中心点相同，在内存缓冲区中将该像素点置白，否则保持不变。</li>
</ul>
<img src="/2022/11/30/ImageProc/image-20221204212230768.png" class="" title="image-20221204212230768"><img src="/2022/11/30/ImageProc/image-20221204212236199.png" class="" title="image-20221204212236199">

<h3 id="边界跟踪法"><a href="#边界跟踪法" class="headerlink" title="边界跟踪法"></a>边界跟踪法</h3><p>边界跟踪的基本方法是：先根据某些严格的“探测准则”找出目标物体轮廓上的像素，再根据这些像素的某些特征用一定的“跟踪准则”找出目标物体上的其他像素。</p>
<p>一般的跟踪准则是：</p>
<ol>
<li> 边缘跟踪从图像左上角开始逐像点扫描，当遇到边缘点时则开始顺序跟踪，直至跟踪的后续点回到起始点（对于闭合线）或其后续点再没有新的后续点（对于非闭合线）为止。</li>
<li>  如果为非闭合线，则跟踪一侧后需从起始点开始朝相反的方向跟踪到另一尾点。</li>
<li>  如果不止一个后续点，则按上述连接准则选择加权平均最大的点为后续点，另一次要的后续点作为新的边缘跟踪起点另行跟踪。一条线跟踪完后，接着扫描下一个未跟踪点，直至图像内的所有边缘都跟踪完毕。 </li>
</ol>
<img src="/2022/11/30/ImageProc/image-20221204212245143.png" class="" title="image-20221204212245143">

<h3 id="已知形状的曲线检测"><a href="#已知形状的曲线检测" class="headerlink" title="已知形状的曲线检测"></a>已知形状的曲线检测</h3><p>对已知的直线，曲线，圆等形状曲线进行检测，hough变换非常有效。</p>
<p>Hough变换的核心思想</p>
<img src="ImageProc/image-20221204212313420.png" alt="image-20221204212313420" style="zoom:67%;" />

<p>ppt</p>
<h3 id="区域增长法"><a href="#区域增长法" class="headerlink" title="区域增长法"></a>区域增长法</h3><p>基于区域整体特性的图像分割方法。</p>
<p>图像分割的目的是要把一幅图像划分成一些区域，最直接的方法就是把点组成区域。为此需要：</p>
<ul>
<li>确定区域的数目，</li>
<li>确定一个区域与其他区域相区别的特征，</li>
<li>产生有意义分割的相似性判据。</li>
</ul>
<p>区域生长法的依据：假定已知要划分的区域数目以及每个区域内某一点的位置，就可以推导出图像分割的一种算法，即区域生长法。</p>
<p>区域生长法主要考虑象素及其空间邻域象素之间的关系。开始时确定一个或多个象素点作为种子，然后按某种相似性准则增长区域，逐步生成具有某种均匀性的空间区域，将相邻的具有相似性质的象素或区域归并从而逐步增长区域，直至没有可以归并的点或其它小区域为止。区域内象素的相似性度量可以包括平均灰度值、纹理、颜色等信息。 </p>
<img src="/2022/11/30/ImageProc/image-20221204212729992.png" class="" title="image-20221204212729992">

<p>区域生长法示例</p>
<p>下例通过一个印章识别中的印文区域分割例子来具体介绍一种区域生长的方法。</p>
<p>由于盖印时油墨、下垫物等，以及人手用力不均匀，盖出的印章深浅是不相同的。如果用单一阈值进行分割，则会出现对盖印条件过于敏感等问题。</p>
<img src="/2022/11/30/ImageProc/image-20221204212935106.png" class="" title="image-20221204212935106">

<p>如果采用区域生长法，首先选择红色的点为种子点（假设采用红色的印章油墨盖印），然后确定生长准则。</p>
<p>如果采用灰度差准则，则是判断当前点与种子点之间的灰度差，如果小于设定的阈值，就确认为印章点，否则认为是背景点。这样，如图 (b)所示，对盖印较浅的部分，就会产生严重的缺损。如果采用一致性准则，如图 (c)所示，可以一定程度地抵抗盖印不均所带来的影响。</p>
<p>一致性准则是：首先选择若干的红色点为种子点，计算这些点所组成的点集合的灰度均值和方差，然后在判断某个点是否为同一区域时，判断其灰度值与该均值的差，以及该点与种子点之间的方差，如果小于设定阈值，则表明该点与种子点具有一致性，将其判定为印章区域的点。之后，计算增加一个点后的点集合的灰度均值与方差，再进行下一个点的判断。</p>
<h3 id="区域分裂合并法"><a href="#区域分裂合并法" class="headerlink" title="区域分裂合并法"></a>区域分裂合并法</h3><p>区域合并、分裂方法</p>
<p>区域生长法存在问题：区域生长法的最关键一步，就是需要根据先验知识选取<strong>种子点</strong>，这就给一些无法获得先验知识的自动分割的课题带来许多的困难。</p>
<p>区域合并、分裂方法的核心思想是：无需先确定种子点</p>
<p>将图像分成若干的子块，对每个子块的属性进行计算：当属性表明该子块包含不同区域的像素，则该子块再分裂成若干子块。</p>
<p>如果几个子块的属性相似，则这几个相似属性的子块合并成一个大的区域。</p>
<p>基本思想：</p>
<p>先分裂后合并</p>
<p>区域分裂合并方法利用了图像数据的金字塔或四叉树数据结构的层次概念，将图像划分成一组任意不相交的初始区域，即可以从图像的这种金字塔或四叉树数据结构的任一中间层开始，根据给定的均匀性检测准则进行分裂和合并这些区域，逐步改善区域划分的性能，直至最后将图像分成数量最少的均匀区域为止。</p>
<p>区域分裂思想：如果区域的某些特性差别比较大,即不满足一致性准则时,则区域应该采用分裂法,分裂过程从从图像的最大区域开始，一般情况下，是从整幅图像开始。</p>
<p>注意：</p>
<ul>
<li>确定分裂准则(一致性准则，如灰度)</li>
<li>确定分裂方法，即如何分裂区域，使得分裂后的子区域的特性尽可能都满足一致性准则值。</li>
</ul>
<p>算法</p>
<p>定义P:P(Ri)的可定义为</p>
<p>区域内多于80%的像素满足不等式|zj-mi|≤2σi，</p>
<p>其中： R<em>i</em>是第<em>i</em>个区域。zj是区域Ri中第j个点的灰度级，mi是该区域的平均灰度级，σi是区域的灰度级的标准方差。</p>
<p>就定义P(Ri)=TRUE，并将区域Ri内所有像素的灰度级置为mi。</p>
<ol>
<li>形成初始区域</li>
<li>对图像的每一个区域<em>R**i</em>，计算<em>P</em>(<em>R**i</em>)，如果</li>
<li><em>P</em>(<em>R**i</em>)=FALSE</li>
<li>则沿着某一合适的边界分裂区域</li>
<li>重复步骤2，当没有区域需分裂时，算法结束。</li>
</ol>
<p>分裂的存在的问题：单纯的区域分裂只能把图像分成许多满足一致性的区域,相邻的具有相同性质的区域并没有合成一体。</p>
<p>区域合并基本思想：因此分裂完成后，再将具有相同性质区域合并。</p>
<ul>
<li>合并运算就是把相邻的具有相似性质的区域合成为一个区域</li>
<li>合并算法中最重要的运算：确定两个区域的相似性</li>
<li>判定区域相似性方法：<ul>
<li>可以基于区域的灰度值，</li>
<li>可以基于区域边界的强弱性等因素。</li>
<li>一种简单的方法是比较它们的灰度均值</li>
</ul>
</li>
</ul>
<p>算法</p>
<ol>
<li>使用某种方法进行图像的初始区域分割。</li>
<li>对于图像中相邻的区域，计算是否满足一致性,若满足则合并为一个区域。</li>
<li>重复步骤2，直到没有区域可以合并，算法结束。</li>
</ol>
<img src="/2022/11/30/ImageProc/image-20221204213343877.png" class="" title="image-20221204213343877">

<img src="/2022/11/30/ImageProc/image-20221204213351615.png" class="" title="image-20221204213351615">

<p>失去耐心.jpg</p>
<img src="/2022/11/30/ImageProc/image-20221204213406551.png" class="" title="image-20221204213406551">

<p>整个算法步骤</p>
<ol>
<li>设整幅图像为初始区域</li>
<li>对每一区域<em>R</em>，如果<em>P</em>(<em>R</em>)=FLASE，则把该区域分裂成四个子区域</li>
<li>重复上一步，直到没有区域可以分裂</li>
<li>对图像中任意两个相邻的<em>R</em>1和<em>R</em>2，如果<em>P</em>(<em>R</em>1U<em>R</em>2)=TRUE，则把这两个区域合并成一个区域。</li>
<li>重复上一步，直到没有相邻区域可以合并，算法结束</li>
</ol>
<img src="/2022/11/30/ImageProc/image-20221204213442283.png" class="" title="image-20221204213442283">

<img src="/2022/11/30/ImageProc/image-20221204213451659.png" class="" title="image-20221204213451659">

<img src="/2022/11/30/ImageProc/image-20221204213504538.png" class="" title="image-20221204213504538">

<p>区域合并、分裂方法</p>
<ul>
<li>根据σ的值进行判别，如果设定阈值为σTh=1，可知f11，f12不再分裂，而f13和f14进行下一层的分裂，刚好分裂到最小单位为单个像素。</li>
<li>然后，以灰度差小于μTh=2为基准进行合并，可以得到下面的图像分割结果。</li>
</ul>
<h2 id="8-3模板匹配"><a href="#8-3模板匹配" class="headerlink" title="8.3模板匹配"></a>8.3模板匹配</h2><p>？没有</p>
<h2 id="8-4图像的测量"><a href="#8-4图像的测量" class="headerlink" title="8.4图像的测量"></a>8.4图像的测量</h2><p>几个基本概念：</p>
<p>(1)邻域</p>
<p> 与像素(x,y)对应的点集合{(x+p,y+q);((p,q)是一对有意义的整数)}称之为像素(x,y)的邻域。离散图像处理中常取4邻域和8邻域. </p>
<p>(2)连通</p>
<img src="/2022/11/30/ImageProc/image-20230207125538645.png" class="" title="image-20230207125538645">

<p> (3)连通成份 </p>
<p> 二值图像中互相连通的0-像素集或1-像素集称之为连通成份。 </p>
<p>孔：在“0”连接成分中，如果存在与外围的一行、一列的像素不连接成分， 则称为孔。如a，b。</p>
<p>单连接成分：不包含孔的“1”连接成分称为单连接成分；</p>
<p>孤立点：仅含有一个像素的“1”单连接成分；</p>
<p>多重连接成分：含有孔的“1”连接成分称为多连接成分。</p>
<p>3．欧拉数</p>
<p>  在二值图像中，1像素连接成分数C减去孔数H的值叫做这幅图像的欧拉数或示性数。若用E表示图像的欧拉数，则</p>
<p>​        E=C-H         (8.1-1)</p>
<p>E是欧拉数，C是连通成分数，H是孔数</p>
<p>欧拉数：对于一个1像素连接成分，1减去这个连接成分中所包含的孔数的差值叫做这个1像素连接成分的欧拉数。二值图像的欧拉数是所有1像素连接成分的欧拉数之和。</p>
 <img src="/2022/11/30/ImageProc/image-20230207125625489.png" class="" title="image-20230207125625489">

<p>4．像素的可删除性和连接数</p>
<p>   二值图像上改变一个像素的值后也就是删除这个像素，整个图像的连接性并不改变（各连接成分既不分离、不结合，孔也不产生、不消失），则这个像素是可删除的。</p>
<p>5、交叉数：是表征当前像素的八个近邻像素中，从像素值为1的点到像素值为0的点的变化次数。</p>
<p>6.距离：对于集合S中的两个元素<em>p</em>和<em>q</em>，当函数<em>D</em> ( <em>p</em> , <em>q</em> )满足下式的条件时，把<em>D</em> ( <em>p</em> , <em>q</em> )叫做<em>p</em>和<em>q</em>的距离，也称为距离函数。</p>
<img src="/2022/11/30/ImageProc/image-20230207125725953.png" class="" title="image-20230207125725953">

<p>7、链码</p>
<p>一种矢量表示法，具有方向性；</p>
<p>是相互邻接的两个像素按照不同的方向给定一个规定的数字符号（码）。</p>
<p>用一串这样的符号（码）表示一个连接成分的方法叫 链码表示法。</p>
 <img src="/2022/11/30/ImageProc/image-20230207125756900.png" class="" title="image-20230207125756900">

<p><strong>连接成分的标记：</strong>为区分二值图像中的连接成分，求得连接成分个数，</p>
<p>对属于同一个１像素连接成分的所有像素分配相同的编号，对不同的连接成分分配不同的编号的操作。</p>
<p>即分割后的一帧图像内可能存在多个连通成份/域，每个非连通成份/域都对应一个目标图像区，给各目标图像区分配相应标号的工作称之为标记。</p>
<img src="/2022/11/30/ImageProc/image-20230207125904472.png" class="" title="image-20230207125904472">

<p>l4连通加标记的一种方法</p>
<p>说明：图中A代表物体，0代表背景，规定用四连通加标记，由于扫描的次序，对于任意点，其左前一点和上一点一定是扫描过的点。</p>
<p>标记原则：</p>
<ul>
<li>当左前一点和上一点都是背景0时，则当前点加新标记。</li>
<li>当左前一点和上一点有一个是0时，另一个已加过标记，则当前点和已加标记点有相同标记。</li>
<li>当左前一点和上一点都是已加标记点，则当前点标记和左前点相同。</li>
</ul>
<p>标记方法：</p>
<p> 标记直接修改像素值为1，2，3，4…</p>
<img src="/2022/11/30/ImageProc/image-20230207125948428.png" class="" title="image-20230207125948428">



<h1 id="Chapter9-二值图像处理"><a href="#Chapter9-二值图像处理" class="headerlink" title="Chapter9.二值图像处理"></a>Chapter9.二值图像处理</h1><h2 id="9-1数学形态学基础"><a href="#9-1数学形态学基础" class="headerlink" title="9.1数学形态学基础"></a>9.1数学形态学基础</h2><p>数学形态学的数学基础和所用语言是集合论。数学形态学的主要内容是设计一套变换、概念、算法用来描述图像的基本特征。</p>
<p>基本思想是用具有一定形态的结构元素去量度和提取图像中的对应形状以达到对图像分析和识别的目的。</p>
<p>元素和集合</p>
<p>把一幅图像称为一个集合。</p>
<p>对于二值图像，习惯上景物取值为1，用阴影表示，背景取值为0，用白色表示。</p>
<p>值为1的点的集合A与图像是一一对应的。</p>
<p>对于图像A，点a在A区域内， 则a是A的元素，记为<em>a</em>∈A，否则，记作<em>a</em>∈A。</p>
<img src="/2022/11/30/ImageProc/image-20230207130420104.png" class="" title="image-20230207130420104">

<p>基本运算：膨胀、腐蚀</p>
<p>膨胀或腐蚀反复使用就可以清除二值图像中的小成份或孔。</p>
<img src="/2022/11/30/ImageProc/image-20230207130506300.png" class="" title="image-20230207130506300">

<h3 id="腐蚀"><a href="#腐蚀" class="headerlink" title="腐蚀"></a>腐蚀</h3><p>腐蚀是数学形态学的两个基本运算之一，</p>
<p>作用：消除物体边界点，使边界向内部收缩的过程。可以把小于结构元素的物体去除。</p>
<p>设计：选取不同大小的结构元素，就可以去除不同大小的物体。</p>
<p>一种应用：若两个物体间有细小的连通，通过腐蚀可将两个物体分开。</p>
<img src="/2022/11/30/ImageProc/image-20230207130649708.png" class="" title="image-20230207130649708">

<p>  <em>X</em>用<em>S</em> 腐蚀的结果是所有使<em>S</em> 平移<em>x</em>后仍在<em>X</em> 中的<em>x</em>的集合。</p>
<p>腐蚀在数学形态学运算中的作用是消除物体边界点。</p>
<p>腐蚀可以把小于结构元素的物体(毛刺、 小凸起)去除;</p>
<p>如果两个物体之间有细小的连通，结构元素足够大时，通过腐蚀运算可以将两个物体分开。</p>
<img src="/2022/11/30/ImageProc/image-20230207130922708.png" class="" title="image-20230207130922708">

<img src="/2022/11/30/ImageProc/image-20230207130955000.png" class="" title="image-20230207130955000">

<img src="/2022/11/30/ImageProc/image-20230207131005119.png" class="" title="image-20230207131005119">

<img src="/2022/11/30/ImageProc/image-20230207131012027.png" class="" title="image-20230207131012027">

<h3 id="膨胀"><a href="#膨胀" class="headerlink" title="膨胀"></a>膨胀</h3><p>膨胀的方法：拿S的中心点和X上的点及X周围的点一个一个地对，如果S上有一个点落在X的范围内，则该点存在且为黑。</p>
<p>（图有小错误）</p>
<img src="/2022/11/30/ImageProc/image-20230207131139098.png" class="" title="image-20230207131139098">

<p>用腐蚀和膨胀运算还可以实现图像的平移。如果在自定义结构元素时选择不在原点的一个点作为结构元素，则得到的图像形状没有任何改变，只是位置发生了移动。</p>
<img src="/2022/11/30/ImageProc/image-20230207131234088.png" class="" title="image-20230207131234088">

<h3 id="开-闭运算"><a href="#开-闭运算" class="headerlink" title="开/闭运算"></a>开/闭运算</h3><p>膨胀和腐蚀不互为逆运算，可以级连结合使用，构造出形态学运算族，它由膨胀和腐蚀两个运算的复合与集合操作组合成的所有运算构成。</p>
<p>  例如，可先对图像进行腐蚀然后膨胀其结果，称为开运算，或先对图像进行膨胀然后腐蚀其结果，称为闭运算。开运算和闭运算是形态学运算族中两个最为重要的组合运算。 </p>
<img src="/2022/11/30/ImageProc/image-20230207131358420.png" class="" title="image-20230207131358420">

<img src="/2022/11/30/ImageProc/image-20230207131414847.png" class="" title="image-20230207131414847">

<img src="/2022/11/30/ImageProc/image-20230207131419942.png" class="" title="image-20230207131419942">

<h3 id="击中-击不中"><a href="#击中-击不中" class="headerlink" title="击中/击不中"></a>击中/击不中</h3><img src="/2022/11/30/ImageProc/image-20230207131451735.png" class="" title="image-20230207131451735">

<img src="/2022/11/30/ImageProc/image-20230207131459147.png" class="" title="image-20230207131459147">

<img src="/2022/11/30/ImageProc/image-20230207131551698.png" class="" title="image-20230207131551698">

<img src="/2022/11/30/ImageProc/image-20230207131604942.png" class="" title="image-20230207131604942">

<p>   由此可见，击中运算相当于一种条件比较严格的模板匹配，它不仅指出被匹配点所应满足的性质即模板的形状，同时也指出这些点所不应满足的性质，即对周围环境背景的要求。</p>
<img src="/2022/11/30/ImageProc/image-20230207131629667.png" class="" title="image-20230207131629667">

<h2 id="9-2图像几何测量"><a href="#9-2图像几何测量" class="headerlink" title="9.2图像几何测量"></a>9.2图像几何测量</h2><h3 id="面积"><a href="#面积" class="headerlink" title="面积"></a>面积</h3><h3 id="周长"><a href="#周长" class="headerlink" title="周长"></a>周长</h3><img src="/2022/11/30/ImageProc/image-20230207131829944.png" class="" title="image-20230207131829944">

<img src="/2022/11/30/ImageProc/image-20230207131835808.png" class="" title="image-20230207131835808">



<p>周长是围绕所有像素的外边界的长度。常用简便方法如下： </p>
<p> (1) 把图像中的像素看作单位面积小方块，图像中的区域和背景均由小方块组成。区域的周长为区域和背景缝隙的长度和，此时边界用隙码表示。求周长就是计算隙码的长度。</p>
<img src="/2022/11/30/ImageProc/image-20230207131922188.png" class="" title="image-20230207131922188">

<p>  (2) 把像素看作一个个点时，周长用链码表示，求周长也即计算链码长度。当链码值为奇数时，其长度记作√2；当链码值为偶数时，其长度记作1。即周长<em>p</em>表示为 </p>
<img src="/2022/11/30/ImageProc/image-20230207131951128.png" class="" title="image-20230207131951128">

<p>  (3) 周长用边界所占面积表示，也即边界点数之和， 每个点占面积为1的一个小方块。(实际就是像素点个数，简单实用）</p>
<img src="/2022/11/30/ImageProc/image-20230207132440663.png" class="" title="image-20230207132440663">

<p>质心、形状特征、矩形度、长宽比、圆形度、致密度、球状性、见ppt</p>

      </section>

      
      
        <nav class="article-nav">
          
            <div class="article-nav-item layout-padding">
  <article class="card-container article-nav-card content-padding--primary soft-size--large soft-style--box">
    
    <div class="card-text">
      
        <a href="/2022/12/09/ImageProcCode/" itemprop="url">
          <h2 class="card-text--title text-ellipsis">数字图像处理课设</h2>
        </a>
      
      <div class="card-text--row">Newer</div>
    </div>
  </article>
</div>
          
          
            <div class="article-nav-item layout-padding">
  <article class="card-container article-nav-card content-padding--primary soft-size--large soft-style--box">
    
    <div class="card-text">
      
        <a href="/2022/11/27/oraclesql/" itemprop="url">
          <h2 class="card-text--title text-ellipsis">oracle数据库</h2>
        </a>
      
      <div class="card-text--row">Older</div>
    </div>
  </article>
</div>
          
        </nav>
      

      <section class="page-message-container layout-padding">
        


  
  

  
  


      </section>
    </div>
    <div class="widget-info">
      <section class="widget-author widget-item layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-body">
    
      <img src="/img/avator.png" class="soft-size--round soft-style--box" alt="STERNE">
    
    
      <h2>STERNE</h2>
    
    
      <p>SDUer，大一入门，大二入土，大三老东西！</p>
    

    <div class="count-box">
      <div class="count-box--item">
        <svg class="icon icon-article" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M240.51564747 647.74217627h196.07203239c16.59071043 0 30.16492806-13.57421762 30.16492805-30.16492806V165.10332731c0-33.18142087-30.16492806-60.32985613-60.32985612-60.32985611H245.04038668C225.43318342 104.7734712 210.35071939 119.85593522 210.35071939 139.46313845V617.57724821c0 16.59071043 13.57421762 30.16492806 30.16492808 30.16492806z m663.62841731-452.47392089v482.63884894c0 33.18142087-27.14843525 60.32985613-60.32985612 60.32985613H180.18579134c-33.18142087 0-60.32985613-27.14843525-60.32985612-60.32985613V195.26825538c-49.77213131 0-90.49478418 40.72265287-90.49478417 90.49478417v452.4739209c0 49.77213131 40.72265287 90.49478418 90.49478417 90.49478417h286.56681657c16.59071043 0 30.16492806 13.57421762 30.16492807 30.16492807s13.57421762 30.16492806 30.16492805 30.16492806h90.49478418c16.59071043 0 30.16492806-13.57421762 30.16492805-30.16492806s13.57421762-30.16492806 30.16492807-30.16492807h286.56681657c49.77213131 0 90.49478418-40.72265287 90.49478417-90.49478417V285.76303955c0-49.77213131-40.72265287-90.49478418-90.49478417-90.49478417zM587.41232014 647.74217627h191.54729318c19.60720323 0 34.68966726-15.08246403 34.68966729-34.68966727V134.93839925c0-16.59071043-13.57421762-30.16492806-30.16492808-30.16492805H617.57724821c-30.16492806 0-60.32985613 27.14843525-60.32985612 60.32985611v452.4739209c0 16.59071043 13.57421762 30.16492806 30.16492805 30.16492806z" fill="currentColor"></path>
</svg>
        <span>59</span>
      </div>
      <div class="count-box--item">
        <svg class="icon icon-categories" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M900.3614811 257.09082106h-339.81629553l-67.96326003-101.9448889c-19.41807444-29.12711113-48.54518557-43.69066667-82.52681443-43.69066667H123.6385189c-53.39970333 0-97.09036999 43.69066667-97.09037113 97.09036999v582.54222222c0 53.39970333 43.69066667 97.09036999 97.09037113 97.09037002h776.7229622c53.39970333 0 97.09036999-43.69066667 97.09037113-97.09037002V354.18119104c0-53.39970333-43.69066667-97.09036999-97.09037113-97.09036998z m-97.09036999 242.72592554H220.72888889c-24.27259221 0-48.54518557-24.27259221-48.54518556-48.54518556s24.27259221-48.54518557 48.54518556-48.54518444h582.54222222c24.27259221 0 48.54518557 24.27259221 48.54518556 48.54518444s-24.27259221 48.54518557-48.54518556 48.54518556z" fill="currentColor"></path>
</svg>
        1
      </div>
      <div class="count-box--item">
        <svg class="icon icon-tags" viewBox="0 0 1098 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M283.42180005 272q0-28.38857157-20.09142843-48.48000001t-48.47999998-20.09142842-48.48000002 20.09142842-20.09142846 48.48000001 20.09142846 48.48 48.48000002 20.09142843 48.47999998-20.09142843 20.09142843-48.48zM855.0332285 580.57142843q0 28.38857157-19.81714313 48.2057147l-263.03999997 263.58857157q-20.9142853 19.81714313-48.75428534 19.81714312-28.38857157 0-48.20571468-19.81714312l-383.04-383.58857157q-20.36571468-19.81714313-34.55999999-54.10285688t-14.19428534-62.6742853l0-222.85714313q0-27.84000002 20.36571469-48.20571469t48.2057147-20.36571466l222.85714313 0q28.38857157 0 62.6742853 14.19428529t54.65142842 34.55999999l383.04000001 382.49142843q19.81714313 20.9142853 19.81714314 48.75428532zM1060.74751475 580.57142843q0 28.38857157-19.81714313 48.2057147l-263.04 263.58857157q-20.9142853 19.81714313-48.75428531 19.81714312-19.26857155 0-31.61142843-7.47428531t-28.38857159-24.13714314l251.79428534-251.7942853q19.81714313-19.81714313 19.81714308-48.20571469 0-27.84000002-19.81714308-48.75428531l-383.04000001-382.49142845q-20.36571468-20.36571468-54.65142842-34.55999999t-62.67428532-14.19428534l120 0q28.38857157 0 62.67428532 14.19428534t54.65142842 34.55999999l383.03999998 382.49142845q19.81714313 20.9142853 19.81714314 48.75428531z" fill="currentColor"></path>
</svg>
        21
      </div>
    </div>
  </div>
</section>

      

      
<section class="widet-notice widget-item layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-title">
    <svg class="icon icon-notice" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M512 945.02305225v28.15620663a24.27259221 24.27259221 0 0 1-24.27259221 24.27259335H394.0352a48.54518557 48.54518557 0 0 1-41.74885888-23.78714112l-110.68302222-184.47170332a132.04290333 132.04290333 0 0 1-17.47626667-48.54518557h118.4502511a200.97706667 200.97706667 0 0 1 76.21594113 14.56355556l20.38897777 133.49925888a48.54518557 48.54518557 0 0 0 36.40888888 27.67075555l16.01991111 2.91271112a24.27259221 24.27259221 0 0 1 20.38897778 25.72894889zM997.45185223 463.45481443a194.18074112 194.18074112 0 0 1-38.8361489 116.50844445 24.75804445 24.75804445 0 0 1-36.4088889 0l-34.95253333-34.95253333a24.27259221 24.27259221 0 0 1-2.91271111-30.58346667 97.09036999 97.09036999 0 0 0 0-106.79940665 24.27259221 24.27259221 0 0 1 2.91271111-30.58346666l34.95253333-34.95253334a24.75804445 24.75804445 0 0 1 18.93262223-7.28177777 26.2144 26.2144 0 0 1 17.47626667 9.70903665A194.18074112 194.18074112 0 0 1 997.45185223 463.45481443z m-194.18074112-388.36148111v776.72296335a48.54518557 48.54518557 0 0 1-48.54518556 48.54518443h-28.64165888a48.54518557 48.54518557 0 0 1-33.98163001-14.07810332l-145.63555556-143.20829668A291.27111111 291.27111111 0 0 0 342.57730333 657.63555556H172.18370333a145.63555556 145.63555556 0 0 1-145.63555556-145.63555556v-97.09036999a145.63555556 145.63555556 0 0 1 145.63555556-145.63555556h170.3936a291.27111111 291.27111111 0 0 0 206.31703779-85.43952668l145.63555555-143.20829554a48.54518557 48.54518557 0 0 1 33.98162888-14.07810446H754.72592555a48.54518557 48.54518557 0 0 1 48.54518556 48.54518555z" fill="currentColor"></path>
</svg>
    <span>NOTICE</span>
  </div>
  <div class="widget-body">
    <p>这里还什么都没有呢喵~</p>
  </div>
</section>


      <section class="widget-categorys widget-item layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-title">
    <svg class="icon icon-categories" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M900.3614811 257.09082106h-339.81629553l-67.96326003-101.9448889c-19.41807444-29.12711113-48.54518557-43.69066667-82.52681443-43.69066667H123.6385189c-53.39970333 0-97.09036999 43.69066667-97.09037113 97.09036999v582.54222222c0 53.39970333 43.69066667 97.09036999 97.09037113 97.09037002h776.7229622c53.39970333 0 97.09036999-43.69066667 97.09037113-97.09037002V354.18119104c0-53.39970333-43.69066667-97.09036999-97.09037113-97.09036998z m-97.09036999 242.72592554H220.72888889c-24.27259221 0-48.54518557-24.27259221-48.54518556-48.54518556s24.27259221-48.54518557 48.54518556-48.54518444h582.54222222c24.27259221 0 48.54518557 24.27259221 48.54518556 48.54518444s-24.27259221 48.54518557-48.54518556 48.54518556z" fill="currentColor"></path>
</svg>
    <span>CATEGORYS</span>
  </div>
  <div class="widget-body">
    <ul class="categorys-list">
      
        <li class="categorys-list-item">
          <a href="/categories/%E5%B8%AE%E5%8A%A9%E6%96%87%E6%A1%A3/">
            帮助文档 (5)
          </a>
        </li>
      
    </ul>
  </div>
</section>

      <section class="widget-tags widget-item  layout-margin content-padding--primary soft-size--large soft-style--box">
  <div class="widget-title">
    <svg class="icon icon-tags" viewBox="0 0 1098 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M283.42180005 272q0-28.38857157-20.09142843-48.48000001t-48.47999998-20.09142842-48.48000002 20.09142842-20.09142846 48.48000001 20.09142846 48.48 48.48000002 20.09142843 48.47999998-20.09142843 20.09142843-48.48zM855.0332285 580.57142843q0 28.38857157-19.81714313 48.2057147l-263.03999997 263.58857157q-20.9142853 19.81714313-48.75428534 19.81714312-28.38857157 0-48.20571468-19.81714312l-383.04-383.58857157q-20.36571468-19.81714313-34.55999999-54.10285688t-14.19428534-62.6742853l0-222.85714313q0-27.84000002 20.36571469-48.20571469t48.2057147-20.36571466l222.85714313 0q28.38857157 0 62.6742853 14.19428529t54.65142842 34.55999999l383.04000001 382.49142843q19.81714313 20.9142853 19.81714314 48.75428532zM1060.74751475 580.57142843q0 28.38857157-19.81714313 48.2057147l-263.04 263.58857157q-20.9142853 19.81714313-48.75428531 19.81714312-19.26857155 0-31.61142843-7.47428531t-28.38857159-24.13714314l251.79428534-251.7942853q19.81714313-19.81714313 19.81714308-48.20571469 0-27.84000002-19.81714308-48.75428531l-383.04000001-382.49142845q-20.36571468-20.36571468-54.65142842-34.55999999t-62.67428532-14.19428534l120 0q28.38857157 0 62.67428532 14.19428534t54.65142842 34.55999999l383.03999998 382.49142845q19.81714313 20.9142853 19.81714314 48.75428531z" fill="currentColor"></path>
</svg>
    <span>TAGS</span>
  </div>
  <div class="widget-body">
    <div class="tags-cloud">
      <a href="/tags/ACM/" style="font-size: 14.44px;" class="tags-cloud-4">ACM</a> <a href="/tags/Arc/" style="font-size: 11.11px;" class="tags-cloud-1">Arc</a> <a href="/tags/CCPC/" style="font-size: 13.33px;" class="tags-cloud-3">CCPC</a> <a href="/tags/HPC/" style="font-size: 10px;" class="tags-cloud-0">HPC</a> <a href="/tags/bot/" style="font-size: 10px;" class="tags-cloud-0">bot</a> <a href="/tags/c/" style="font-size: 12.22px;" class="tags-cloud-2">c</a> <a href="/tags/cpp/" style="font-size: 20px;" class="tags-cloud-10">cpp</a> <a href="/tags/deeplearning/" style="font-size: 15.56px;" class="tags-cloud-6">deeplearning</a> <a href="/tags/games/" style="font-size: 12.22px;" class="tags-cloud-2">games</a> <a href="/tags/hexo/" style="font-size: 11.11px;" class="tags-cloud-1">hexo</a> <a href="/tags/java/" style="font-size: 11.11px;" class="tags-cloud-1">java</a> <a href="/tags/maths/" style="font-size: 10px;" class="tags-cloud-0">maths</a> <a href="/tags/note/" style="font-size: 11.11px;" class="tags-cloud-1">note</a> <a href="/tags/pyqt/" style="font-size: 10px;" class="tags-cloud-0">pyqt</a> <a href="/tags/python/" style="font-size: 17.78px;" class="tags-cloud-8">python</a> <a href="/tags/qt/" style="font-size: 10px;" class="tags-cloud-0">qt</a> <a href="/tags/recommends/" style="font-size: 10px;" class="tags-cloud-0">recommends</a> <a href="/tags/review/" style="font-size: 16.67px;" class="tags-cloud-7">review</a> <a href="/tags/sql/" style="font-size: 18.89px;" class="tags-cloud-9">sql</a> <a href="/tags/srtp/" style="font-size: 10px;" class="tags-cloud-0">srtp</a> <a href="/tags/test/" style="font-size: 10px;" class="tags-cloud-0">test</a>
    </div>
  </div>
</section>
    </div>
  </article>
</div>

    <!-- footer container -->
<footer id="footer" class="footer">
  <div class="footer-container">
    
    <div class="social-icons">
      
        
      
        
      
        
      
        
          <a href="https://github.com/sterne012" class="soft-size--primary soft-style--box" target="_blank" rel="noopener noreferrer">
            <svg class="icon icon-github" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M64.6 512c0 195.6 125.4 361.9 300.1 422.9 23.5 5.9 19.9-10.8 19.9-22.2v-77.6c-135.8 15.9-141.3-74-150.5-89-18.5-31.5-61.9-39.5-49-54.5 31-15.9 62.5 4 98.9 58 26.4 39.1 77.9 32.5 104.1 26 5.7-23.5 17.9-44.5 34.7-60.9-140.7-25.2-199.4-111.1-199.4-213.3 0-49.5 16.4-95.1 48.4-131.8-20.4-60.6 1.9-112.4 4.9-120.1 58.2-5.2 118.5 41.6 123.3 45.3 33.1-8.9 70.8-13.7 112.9-13.7 42.4 0 80.3 4.9 113.5 13.9 11.3-8.6 67.3-48.8 121.4-43.9 2.9 7.7 24.7 58.3 5.5 118.1 32.5 36.8 49 82.8 49 132.4 0 102.3-59 188.3-200.2 213.2 23.5 23.3 38.1 55.5 38.1 91.1v112.7c0.8 9 0 17.9 15.1 17.9C832.7 877 960.4 709.4 960.4 512.1c0-247.5-200.6-447.9-447.9-447.9C265 64.1 64.6 264.5 64.6 512z"></path>
</svg>
          </a>
        
      
        
          <a href="https://twitter.com/sterne012" class="soft-size--primary soft-style--box" target="_blank" rel="noopener noreferrer">
            <svg class="icon icon-twitter" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M962.285714 233.142857q-38.285714 56-92.571429 95.428571 0.571429 8 0.571429 24 0 74.285714-21.714286 148.285714t-66 142-105.428571 120.285714-147.428571 83.428571-184.571429 31.142857q-154.857143 0-283.428571-82.857143 20 2.285714 44.571429 2.285714 128.571429 0 229.142857-78.857143-60-1.142857-107.428571-36.857143t-65.142857-91.142857q18.857143 2.857143 34.857143 2.857143 24.571429 0 48.571429-6.285714-64-13.142857-106-63.714286t-42-117.428571l0-2.285714q38.857143 21.714286 83.428571 23.428571-37.714286-25.142857-60-65.714286t-22.285714-88q0-50.285714 25.142857-93.142857 69.142857 85.142857 168.285714 136.285714t212.285714 56.857143q-4.571429-21.714286-4.571429-42.285714 0-76.571429 54-130.571429t130.571429-54q80 0 134.857143 58.285714 62.285714-12 117.142857-44.571429-21.142857 65.714286-81.142857 101.714286 53.142857-5.714286 106.285714-28.571429z"></path>
</svg>
          </a>
        
      
    </div>
     
    <p>&copy; 2023 <a href="/" target="_blank">sterne</a></p>

    

    <p>Powered by <a href="https://hexo.io" target="_blank" rel="noopener noreferrer">Hexo</a> Theme - <a href="https://github.com/miiiku/flex-block" target="_blank" rel="noopener noreferrer author">flex-block</a></p>

    <p>
      <a href="javascript:;" id="theme-light">🌞 浅色</a>
      <a href="javascript:;" id="theme-dark">🌛 深色</a>
      <a href="javascript:;" id="theme-auto">🤖️ 自动</a>
    </p>
  </div>
</footer>
  </div>

  <div class="back-to-top-fixed soft-size--round soft-style--box">
    <svg class="icon icon-back-to-top" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
      <path d="M725.333333 426.666667c-12.8 0-21.333333-4.266667-29.866667-12.8l-213.333333-213.333333c-17.066667-17.066667-17.066667-42.666667 0-59.733333s42.666667-17.066667 59.733333 0l213.333333 213.333333c17.066667 17.066667 17.066667 42.666667 0 59.733333C746.666667 422.4 738.133333 426.666667 725.333333 426.666667z"></path>
      <path d="M298.666667 426.666667c-12.8 0-21.333333-4.266667-29.866667-12.8-17.066667-17.066667-17.066667-42.666667 0-59.733333l213.333333-213.333333c17.066667-17.066667 42.666667-17.066667 59.733333 0s17.066667 42.666667 0 59.733333l-213.333333 213.333333C320 422.4 311.466667 426.666667 298.666667 426.666667z"></path>
      <path d="M512 896c-25.6 0-42.666667-17.066667-42.666667-42.666667L469.333333 170.666667c0-25.6 17.066667-42.666667 42.666667-42.666667s42.666667 17.066667 42.666667 42.666667l0 682.666667C554.666667 878.933333 537.6 896 512 896z"></path>
    </svg>
  </div>

  
  <!-- aplayer -->


<!-- dplayer -->




  


  


  




<script src="/js/script.js"></script>


  
  <!-- 尾部用户自定义相关内容 -->
</body>
</html>